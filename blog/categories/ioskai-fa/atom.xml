<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[类别：ios开发 | 第七章]]></title>
  <link href="http://kobe1941.github.io/blog/categories/ioskai-fa/atom.xml" rel="self"/>
  <link href="http://kobe1941.github.io/"/>
  <updated>2023-09-27T21:30:35+08:00</updated>
  <id>http://kobe1941.github.io/</id>
  <author>
    <name><![CDATA[第七章]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[《深入理解计算机系统》]]></title>
    <link href="http://kobe1941.github.io/blog/computer-system-deep.html"/>
    <updated>2019-12-27T22:34:42+08:00</updated>
    <id>http://kobe1941.github.io/blog/computer-system-deep</id>
    <content type="html"><![CDATA[<p>这本书应该是要配合实验才能理解的更加深刻。不过可惜只是过了一遍理论。。</p>

<p>第三章，第七章和第九章的内容比较有意思，相对来说对实际编程的帮助会更大一些，整体上本书可以当做参考书，有需要的时候来查一下还是很不错的。</p>

<p>ps：循环是用类似goto语句的原理（jump指令）实现的。</p>

<!--more-->

<h2 id="section">名词解释</h2>

<p>ALU：算数逻辑单元。</p>

<p>ISA：instruction Set Architecture 指令集体系结构或指令集架构</p>

<p>CISC：复杂指令集计算机</p>

<p>RISC：精简指令集计算机</p>

<p>PCI：Peripheral Component Interconnect 外围设备互联</p>

<p>USB：Universal Serial Bus 通用串行总线</p>

<p>NFS：Network File System 网络文件系统</p>

<p>LFU：Least Frequency Used 最不常使用</p>

<p>LRU：Least Recently Used 最近最少使用</p>

<p>ELF：Execute and Linkable Format 可执行可链接格式</p>

<p>ECF：ExceptionalControl Flow 异常控制流</p>

<p>HTTP：Hypertext Transfer Protocol  超文本传输协议</p>

<p>HTML：Hypertext Markup Language 超文本标记语言</p>

<p>MIMIE：Multipurpose Internet Mail Extension 多用途国际邮件扩充协议</p>

<p>URL：Universal Resource Locator  通用资源定位符</p>

<p>URI：Uniform Resource Identifier  统一资源标识符</p>

<h2 id="section-1">第一章  计算机系统漫游</h2>

<p>1.源程序实际上就是一个由值0和1组成的位（又称为比特）序列，8个位被组织成一组，称为字节。每个字节表示程序中的某些文本字符。</p>

<p>2.像hello.c这样只由ASCII字符构成的文件称为文本文件，所有其他文件都称为二进制文件。</p>

<p>3.系统所有的信息——包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由一串比特表示的。区分不同数据对象的唯一方法是我们读到这些数据对象时的上下文。比如，在不同的上下文中，一个同样的字节序列可能表示一个整数、浮点数、字符串或者机器指令。</p>

<p>4.为了在系统上运行hello.c程序，每条c语句都必须被其他程序转化为一系列的低级机器语言指令。然后这些指令按照一种称为可执行目标程序的格式打好包，并以二进制磁盘文件的形式存放起来。目标程序也称为可执行目标文件。</p>

<p>5.在Unix系统上，从源文件到目标文件的转化是由编译器驱动程序完成的。</p>

<p>汇编器将hello.s翻译成机器语言指令。</p>

<p><img src="/images/2019/12/1.jpg" alt="" /></p>

<p>6.贯穿整个系统的是一组电子管道，称作总线。通常总线被设计成传送定长的字节块，也就是字（word）。字中的字节数（即字长）是一个基本的系统参数，各个系统不尽相同。现在大多数机器字长要么是4个字节（32位），要么是8个字节（64位）。</p>

<p>7.控制器是IO设备本身或者系统的主印制电路板（主板）上的芯片组。而适配器则是一块主板插槽上的卡。它们的功能都是在IO总线和IO设备之间传递信息。</p>

<p>8.主存是一个临时存储设备，从逻辑上来说，存储器是一个线性的字节数组，每个字节都有其唯一的地址（数组索引）。</p>

<p>9.处理器CPU是解释（或执行）存储在主存中指令的引擎。处理器的核心是一个大小为一个字的存储设备（或寄存器），称为程序计数器（PC）。在任何时刻，PC都指向主存中的某条机器语言指令（即含有该条指令的地址）。</p>

<p>10.指令集架构描述的是每条机器代码指令的效果；而微体系结构描述的是处理器实际上是如何实现的。</p>

<p>11.利用DMA（直接存储器存取）技术，数据可以不通过处理器而直接从磁盘到达主存。</p>

<p>12.L1和L2高速缓存是用一种叫做静态随机访问存储器（SRAM）的硬件技术实现的。系统可以获得一个很大的存储器，同时访问速度也很快，原因是利用了高速缓存的局部性原理，即程序具有访问局部区域里的数据和代码的趋势。通过让高速缓存里存放可能经常访问的数据，大部分的内存操作都能在快速的高速缓存中完成。</p>

<p>13.我们可以把操作系统看成是应用程序和硬件之间插入的一层软件，所有应用程序对硬件的操作尝试都必须通过操作系统。</p>

<p>14.操作系统有两个基本功能：（1）防止硬件被失控的应用程序滥用；（2）向应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。操作系统通过几个基本的抽象概念（进程、虚拟内存和文件）来实现这两个功能。</p>

<p>15.进程是操作系统对一个正在运行的程序的一种抽象。</p>

<p>16.无论是在单核还是在多核系统中，一个CPU看上去都像是在并发的执行多个进程，这是通过处理器在进程间切换来实现的。操作系统实现这种交错执行的机制称为上下文切换。</p>

<p>17.从一个 进程到另一个进程的转换是由操作系统内核管理的。内核是操作系统代码常驻内存的部分。内核不是一个独立的进程。相反，它是系统管理全部进程所用代码和数据结构的集合。</p>

<p>18.虚拟内存是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占的使用主存。每个进程看到的内存都是一致的，称为虚拟地址空间。</p>

<p>在Linux中，地址空间最上面的区域是保留给操作系统中的代码和数据的（内核），这对所有进程来说都是一样。地址空间的地步区域存放用户进程定义的代码和数据。</p>

<p>大约在地址空间的中间部分是一块用来存放像C标准库和数学库这样的共享库的代码和数据的区域。</p>

<p>位于用户虚拟地址空间顶部的是用户栈。</p>

<p><img src="/images/2019/12/2.jpg" alt="" /></p>

<p><img src="/images/2019/12/3.jpg" alt="" /></p>

<p>19.虚拟内存的运作需要硬件和操作系统软件之间精密复杂的交互，包括对处理器生成的每个地址的硬件翻译。基本思想是把一个进程虚拟内存的内容存储在磁盘上，然后用主存作为磁盘的高速缓存。</p>

<p>20.文件就是字节序列，仅此而已。每个IO设备，包括键盘鼠标显示器甚至网络等等，都可以看成是文件。</p>

<p>21.数字计算机的整个历史中，有两个需求是驱动进步的持续动力：一个是我们想要计算机做的更多，另一个是我们想要计算机运行的更快。</p>

<p>22.并发是一个通用的概念，指一个同时具有多个活动的系统；并行指的是用并发来使一个系统运行得更快。</p>

<p>23.多核处理器是将多个CPU集成到一个集成电路芯片上。</p>

<p>24.超线程，有时称为同时多线程，是一项允许一个CPU执行多个控制流的技术。它涉及CPU某些硬件有多个备份，比如程序计数器和寄存器文件，而其他的硬件部分只有一份。Intel Core i7 处理器可以让每个核执行两个线程，所以一个4核的系统实际上可以并行的执行8个线程。</p>

<p>25.在较低的抽象层次上，现代处理器可以同时执行多条指令的属性称为指令级并行。</p>

<p>26.在流水线（pipelining）中，将执行一条指令所需要的活动划分为不同的步骤，将处理器的硬件组织成一系列的阶段，每个阶段执行一个步骤。这些阶段可以并行的操作，用来处理不同指令的不同部分。如果处理器可以达到比一个周期一条指令更快的执行速率，就称之为超标量处理器。</p>

<p>27.在最低层次上，许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式称为单指令、多数据，即SIMD并行。</p>

<p>28.在处理器里，指令集架构提供了对实际处理器硬件的抽象。</p>

<p>29.三个抽象：文件是对IO设备的抽象，虚拟内存是对程序存储的抽象，而进程是对一个正在运行的程序的抽象。</p>

<p>30.虚拟机，它提供对整个计算机的抽象，包括操作系统，处理器和程序。</p>

<h3 id="section-2">第一部分   程序结构和执行</h3>

<h2 id="section-3">第二章 信息的表示和处理</h2>

<p>1.无符号（unsigned）编码基于传统的二进制表示法，表示大于或等于0的数字。补码编码是表示有符号整数的最常见的方式。浮点数编码是表示实数的科学计数法的以2为基数的版本。</p>

<p>2.大多数计算机使用8位的块，或者字节，作为最小的可寻址的内存单位，而不是访问内存中单独的位。机器级程序将内存视为一个非常大的字节数组，称为虚拟内存。内存中的每个字节都由一个唯一的数字来标识，称为它的地址，所有可能的地址的集合就称为虚拟地址空间。</p>

<p>3.我们将程序称为“32位程序”或“64位程序”时，区别在于该程序是如何编译的，而不是其运行的机器类型。</p>

<p>4.在几乎所有的机器上，多字节对象都被存储为连续的字节徐磊，对象的地址为所使用字节中最小的地址。</p>

<p>5.反汇编器（disassembler）是一种确定可执行程序文件所表示的指令序列的工具。</p>

<p>6.表达式sizeof（T）返回存储一个类型为T的对象所需要的字节数。</p>

<p>7.有一个相应的右移运算 x»k，逻辑右移在左端补k个0，算术右移是在左端补k个最高有效位的值。实际上，几乎所有的编译器/机器组合都对有符号数使用算术右移，而对于无符号数，右移必须是逻辑的。</p>

<p>8.C和C++都支持有符号（默认）和无符号数。Java只支持有符号数。</p>

<p>9.C语言标准并没有要求要用补码形式来表示有符号整数，但是几乎所有的机器都是这么做的。</p>

<p>10.当执行一个运算时，如果它的一个运算数是有符号的而另一个是无符号的，那么C语言会隐式的将有符号参数强制类型转换为无符号数，并假设这两个数都是非负的。</p>

<p>11.有符号数到无符号数的隐式转换，会导致错误或者漏洞的方式，避免这类错误的一种方法就是绝不使用无符号数。</p>

<p>12.由于整数乘法比移位和加法的代价要大得多，许多C语言编译器试图以移位、加法和减法的组合来消除很多整数乘以常数的情况。</p>

<h2 id="section-4">第三章 程序的机器级表示</h2>

<p>1.GCC C语言编译器以汇编代码的形式产生输出，汇编代码是机器代码的文本表示，给出程序中的每一条指令。然后GCC 调用汇编器和链接器，根据汇编代码生成可执行的机器代码。</p>

<p>2.使用现代的优化编译器，最大的优点是，用高级语言编写的程序可以在很多不同的机器上编译和执行，而汇编代码则是与特定机器密切相关的。</p>

<p>3.优化编译器能够重新排列执行顺序，消除不必要的计算，用快速操作替换慢速操作，甚至将递归计算变换成迭代计算。</p>

<p>4.大多数ISA，包括x86-64，将程序的行为描述成好像每条指令都是按顺序执行的，一条指令结束后，下一条再开始。处理器的硬件远比描述的精细复杂，它们并发的执行许多指令，但是可以采取措施保证整体行为与ISA指定的顺序执行的行为完全一致。</p>

<p>5.程序计数器PC给出将要执行的下一条指令在内存中的地址。</p>

<p>6.x86-64的虚拟地址是由64位的字来表示的。在目前的实现中，这些地址的高16位必须设置为0，所以一个地址实际上能够指定的是2^48或256TB范围内的一个字节。操作系统负责管理虚拟地址空间，将虚拟地址翻译成实际处理器内存中的物理地址。</p>

<p>7.机器执行的程序只是一个字节序列，它是对一系列指令的编码。机器对产生这些指令的源代码几乎一无所知。</p>

<p>8.反汇编器（disassembler）只是基于机器代码文件中的字节序列来确定汇编代码。它不需要访问该程序的源代码或汇编代码。</p>

<p>9.16个寄存器如下图，最特别的是栈指针%rsp，用来指明运行时栈的结束位置。</p>

<p>ps：函数的返回值也是存在寄存器里，函数传参一般也用寄存器，不够时才会用栈。</p>

<p><img src="/images/2019/12/4.jpg" alt="" /></p>

<p>10.栈可以实现为一个数组，总是从数组的一端插入和删除元素。这一端被称为栈顶。——也可以实现为链表</p>

<p>11.因为栈和程序代码以及其他形式的程序数据都是放在同一内存中，所以程序可以用标准的内存寻址方法访问栈内的任意位置。</p>

<p>12.处理器通过使用流水线pipelining来获得高性能。</p>

<p>13.汇编中没有循环的指令存在，可以用条件测试和跳转组合起来实现循环的效果。——也就是类似goto或jump指令</p>

<p>14.使用跳转表是一种非常有效的实现多重分支的方法。在我们的例子中，程序可以只是用一次跳转表引用就分支到5个不同的位置。甚至当switch语句有上百种情况的时候，也可以只用一次跳转表访问去处理。</p>

<p>15.C语言过程调用机制的一个关键特性（大多数其他语言也是如此）在于使用了栈数据结构提供的后进先出的内存管理原则。</p>

<p>16.<strong>x86-64的栈向低地址方向增长，而栈指针%rsp指向栈顶元素。当x86-64过程需要的存储空间超出寄存器能够存放的大小时，就会在栈上分配空间。这个部分称为过程的栈帧（stack frame）。大多数过程的栈帧都是定长的，在过程的开始就分配好了。但是有些过程需要变长的栈帧。</strong></p>

<p>17.<strong>将控制从函数P转移到函数Q只需要简单的把程序计数器PC设置为Q的代码的起始位置。不过稍后从Q返回的时候，处理器必须记录好它需要继续P的执行的代码的位置。在x86-64机器中，这个信息是用指令call Q 调用过程Q来记录的。call Q指令会把地址A压入栈中，并将PC设置为Q的起始地址。压入的地址A被称为返回地址，是紧跟在call 指令后面的那条指令的地址。对应的指令ret 会从栈中弹出地址A，并把PC设置为A。——对比下上面函数返回值，函数的返回地址和返回值是不同的</strong></p>

<p>18.x86-64中，可以通过寄存器最多传递6个整形（即整数和指针）参数。如果一个函数有大于6个整形参数，超出6个的部分就要通过栈来传递。有n个整形参数，且n&gt;6，那么就把参数1-6复制到对应的寄存器，把参数7-n 放到栈上，而参数7就位于栈顶。</p>

<p><img src="/images/2019/12/5.jpg" alt="" /></p>

<p>19.作为过程调用的一部分，返回地址被压入栈中。</p>

<p>20.运行时栈提供了一种简单的、在需要时分配、函数完成时释放局部存储的机制。</p>

<p>21.寄存器组是唯一被所有过程共享的资源。虽然在给定时刻只有一个过程是活动的，我们仍然必须确保当一个过程（调用者）调用另一个过程（被调用者）时，被调用者不会覆盖调用者稍后会使用的寄存器值。</p>

<p>根据惯例，寄存器%rbx、%rbp和%r12-%r15被划分为被调用者保存寄存器。当过程P调用过程Q时，Q必须保存这些寄存器的值不变，保证它们的值在Q返回到P时与Q被调用时是一样的。</p>

<p>所有其他的寄存器，除了栈指针%rsp，都分类为调用者保存寄存器：过程P在某个此类寄存器中有局部数据，然后调用过程Q。因为Q可以随意修改这个寄存器，所以在调用之前首先保存好这个数据是P（调用者）的责任。</p>

<p>22.二维数组在内存中按照“行优先”的顺序排列，意味着第0行的所有元素，可以写作A[0]。A[5][3]则可以被看成一个5行3列的二维数组。</p>

<p><img src="/images/2019/12/6.jpg" alt="" /></p>

<p>23.ISO C99引入了一种功能，允许数组的维度是表达式，在数组被分配的时候才计算出来。</p>

<p>24.C语言提供了两种将不同类型的对象组合到一起创建数据类型的机制：结构，用关键字struct来声明，将多个对象集合到一个单位中；联合，用关键字union来声明，允许用几种不同的类型来引用一个对象。</p>

<p>25.类似于数组的实现，结构的所有组成部分都存在在内存中一段连续的区域内，而指向结构的指针就是结构第一个字节的地址。编译器维护关于每个结构类型的信息，指示每个字段的字节偏移。它以这些偏移作为内存引用指令中的位移，从而产生对结构元素的引用。</p>

<p>26.一种情况是，我们事先知道对一个数据结构中的两个不同字段的使用是互斥的，那么将这两个字段声明为联合的一部分，而不是结构的一部分，就会减少分配空间的总量。</p>

<p>27.许多计算机系统对基本数据类型的合法地址做了一些限制，要求某种类型对象的地址必须是某个值K（通常是2、4或8）的倍数。无论数据是否对齐，x86-64硬件都能正确工作。不过Intel还是建议要对齐数据以提高内存系统的性能。对齐原则是任何K字节的基本对象的地址必须是K的倍数。</p>

<p>28.如果数据没有对齐，某些型号的Intel或AMD处理器对于有些实现多媒体操作的SSE指令，就无法正确执行。任何试图以不满足对齐要求的地址来访问内存都会导致异常，默认的行为是程序终止。</p>

<p>因此，任何针对x86-64处理器的编译器和运行时系统都必须保证分配用来保存可能会被SSE寄存器读或写的数据结构的内存，都必须满足16字节对齐。</p>

<p>29.函数指针的值是该函数机器代码表示中第一条指令的地址。</p>

<p>30.如果存储的返回地址的值被破坏了，那么ret指令会导致程序跳转到一个完全意想不到的位置。</p>

<p>31.缓冲区溢出的一个更加致命的使用就是让程序执行它本来不愿意执行的函数。</p>

<p>32.栈随机化的思想使得栈的位置在程序每次运行时都有变化。</p>

<p>在Linux系统中，栈随机化已经变成了标准行为，它是ASLR（地址空间布局随机化）技术中的一种。采用ASLR，每次运行时程序的不同部分，包括程序代码、库代码、栈、全局变量和堆数据，都会被加载到内存的不同区域。</p>

<p>ASLR技术能够增加成功攻击一个系统的难度，但是也不能提供完全的安全保障。</p>

<p>33.随机化，栈保护和限制哪部分内存可以存储可执行代码，是用于最小化程序缓冲区溢出攻击漏洞三种最常见的机制。</p>

<p>34.为了管理变长栈帧，x86-64代码使用寄存器%bp作为帧指针。</p>

<p>35.JOT即时编译，动态的将字节代码序列翻译成机器指令。当代码要执行多次时，这种方法执行起来更快。</p>

<h2 id="section-5">第四章  处理器体系结构</h2>

<p>1.与同一时刻只执行一条指令相比，通过同时处理多条指令的不同部分，处理器可以获得更高的性能。</p>

<p>2.寄存器%rsp被入栈、出栈、调用和返回指令作为栈指针。程序计数器PC存放当前正在执行指令的地址。</p>

<p>3.内存从概念上来说就是一个很大的字节数组，保存着程序和数据。</p>

<p>4.call 指令将返回地址入栈，然后跳到目的地址。ret 指令从这样的调用中返回。nop 指令只是简单的经过各个阶段，除了要将PC加1，不进行任何处理。halt 指令使得处理器状态被设置成HLT，导致处理器停止运行。</p>

<p>5.流水线化的一个重要特性就是提高了系统的吞吐量，也就是单位时间内服务的顾客综述，不过它也会轻微的增加延迟。</p>

<p>6.猜测分支方向并根据猜测开始取指的技术称为分支预测。</p>

<p>分支预测错误会极大的降低程序的性能，因此这就促使我们在可能的时候，要使用条件数据传送而不是条件控制转移。</p>

<p>7.我们的指令集体系结构包括三种不同的内部产生的异常：（1）halt指令；（2）有非法指令和功能码组合的指令；（3）取指或数据读写试图访问一个非法地址。</p>

<h2 id="section-6">第五章  优化程序性能</h2>

<p>1.编写高效程序需要做到以下几点：①我们必须选择一组适当的算法和数据结构。②我们必须编写出编译器能够有效优化以转换成高效可执行代码的源代码。③针对处理运算量特别大的计算，将一个任务分成多个部分，这些部分可以在多核和多处理器的某种组合上并行的计算。</p>

<p>C语言的有些特性，例如执行指针运算和强制类型转换的能力，使得编译器很难对它进行优化。</p>

<p>即使是要利用并行性，每个并行的线程都以最高性能执行也是非常重要的。</p>

<p>2.程序优化的第一步就是消除不必要的工作，这包括不必要的函数调用，条件测试和内存引用。（消除循环的低效率，减少过程调用）</p>

<p>程序优化的第二步，利用处理器提供的指令级并行能力，同时执行多条指令。</p>

<p>3.用内联函数替换优化函数调用。</p>

<p>4.实际的处理器中，是同时对多条指令求值的，这个现象称为指令级并行。在某些设计中，可以有100或更多条指令在处理中。</p>

<h2 id="section-7">第六章   存储器层次结构</h2>

<p>1.具有良好局部性的程序倾向于一次又一次的访问相同的数据项集合，或是倾向于访问邻近的数据项集合。</p>

<p>2.基本的存储技术：SRAM存储器，DRAM存储器，ROM存储器以及旋转的和固态的硬盘。</p>

<p>3.随机访问存储器RAM分为两类：静态的和动态的。静态RAM（SRAM）比动态RAM（DRAM）更快，但也贵的多。SRAM用来作为高速缓存存储器，既可以在CPU芯片上，也可以在片下。DRAM用来作为主存以及图形系统的帧缓冲区。</p>

<p>4.SRAM将每个位存储在一个双稳态的存储器单元里。每个单元是用一个六晶体管电路来实现的。——从不稳定状态开始，电路会迅速的转移到两个稳定状态中的一个。</p>

<p>由于SRAM存储器单元的双稳态特性，只要有电，它就会永远的保持它的值。即使有干扰来扰乱电压，当干扰消除时，电路就会恢复到稳定值。</p>

<p>5.DRAM将每个位存储为对一个电容的充电。这个电容非常小。DRAM存储器可以制造得非常密集——每个单元由一个电容和一个访问晶体管组成。但与SRAM不同，DRAM存储器单元对干扰非常敏感。当电容的电压被扰乱之后，它就永远不会恢复了。暴露在光线下会导致电容电压改变。实际上，数码照相机和摄像机中的传感器本质上就是DRAM单元的阵列。</p>

<p>很多原因会导致漏电，使得DRAM单元在10-100ms的时间内失去电荷。内存系统必须周期性的通过读出，然后重写来刷新内存每一位。</p>

<p><img src="/images/2019/12/7.jpg" alt="" /></p>

<p>6.DRAM芯片封装在内存模块中，它插到主板的扩展槽上。</p>

<p>7.SDRAM 称为同步DRAM。双倍数据速率同步DRAM称为DDR SDRAM，它是SDRAM的一种增强，它通过使用两个时钟沿作为控制信号，从而使DRAM的速度翻倍。不同类型的DDR SDRAM是用提高有效带宽的很小的预取缓冲区的大小来划分的：DDR（2位）、DDR2（4位）、DDR3（8位）。</p>

<p>8.如果断电，DRAM和SRAM会丢失它们的信息。</p>

<p>PROM可编程ROM只能被编程一次。</p>

<p>EPROM可擦写可编程ROM能够被擦除和重编程的次数的数量级可以达到1000次。EEPROM电子可擦除PROM类似于EPROM，能够被编程的次数的数量级可以达到10^5次。</p>

<p>闪存是一类非易失性存储器，基于EEPROM。基于闪存的磁盘驱动器，称为固态硬盘SSD。</p>

<p>存储在ROM设备中的驱动程序通常称为固件firmware。</p>

<p>9.数据流通过称为总线的共享电子电路在处理器和DRAM主存之间来来回回。</p>

<p>10.磁盘是由一个或多个叠放在一起的盘片组成的。每个盘片有两面或者称为表面，每个表面是由一组称为磁道的同心圆组成，每个磁道被划分为一组扇区。</p>

<p>11.磁盘控制器必须对磁盘进行格式化，然后才能在该磁盘上存储数据。格式化包括用标识扇区的信息填写扇区之间的间隙，标识出表面有故障的柱面并且不使用它们，以及在每个区中预留出一组柱面作为备用。如果区中一个或多个柱面在磁盘使用过程中坏掉了，就可以使用这些备用的柱面。因为存在着这些备用的柱面，所以磁盘制造商所说的格式化容量比最大容量要小。</p>

<p>12.CPU使用一种称为内存映射 I/O 的技术来向 I/O 设备发射命令。在使用内存映射 I/O 的系统中，地址空间中有一块地址是为与I/O设备通信保留的。每个这样的地址称为一个 I/O 端口。</p>

<p>13.在磁盘控制器收到来自CPU的读命令后，它将逻辑块号翻译成一个扇区地址，读该扇区的内容，然后将这些内容直接传送到主存，不需要CPU的干涉。设备可以自己执行读或者写总线事务而不需要CPU干涉的过程，称为直接内存访问DMA（Direct Memory Access）。</p>

<p>在DMA传送完成，磁盘扇区的内容被安全的存储在主存中以后，磁盘控制器通过给CPU发送一个中断信号来通知CPU。基本思想是中断会发信号到CPU芯片的一个外部引脚上。这会导致CPU暂停它当前正在做的工作，跳转到一个操作系统例程，这个程序会记录下I/O已经完成，然后将控制返回到CPU被中断的地方。</p>

<p>14.固态硬盘是一种基于闪存的存储技术。一个SSD封装由一个或多个闪存芯片和闪存翻译层组成。</p>

<p>15.随机写很慢，有两个原因。首先，擦除块需要相对较长的时间，1ms级的，比访问页所需时间要高一个数量级。其次，如果写操作试图修改一个包含已经有数据的页p，那么这个块中所有带有用数据的页都必须被复制到一个新（擦除过的）块，然后才能进行对页p的写。</p>

<p>16.不同的存储技术有不同的价格和性能折中。快速存储总是比慢速存储要贵的。SRAM比DRAM贵，DRAM又比磁盘贵的多，SSD位于DRAM和旋转磁盘之间。</p>

<p>DRAM和磁盘的性能滞后于CPU的性能。而且差距实际上是在加大的。</p>

<p>17.多核处理器：无法再像以前一样迅速的增加CPU的时钟频率了，因为如果那样芯片的功耗会太大。解决方法是用多个小处理器核取代单个大核处理器，从而提高性能，每个完整的处理器能够独立的，与其他核并行的执行程序。</p>

<p>18.局部性原理：它们倾向于引用邻近与其他最近引用过的数据项的数据项，或者最近引用过的数据项本身。</p>

<p>局部性通常有两种不同的形式：时间局部性和空间局部性。在一个具有良好时间局部性的程序中，被引用过一次的内存位置很可能在不远的将来再被多次引用。在一个具有良好空间局部性的程序中，如果一个内存位置被引用了一次，那么程序很可能在不远的将来引用附近的一个内存位置。</p>

<p>有良好局部性的程序比局部性差的程序运行的更快。</p>

<p>19.重复引用相同变量的程序有良好的时间局部性。对于具有步长为k的引用模式的程序，步长越小，空间局部性越好。对于取指令来说，循环有好的时间和空间局部性。循环体越小，循环迭代次数越多，局部性越好。</p>

<p>20.固态硬盘在存储器层级结构中扮演着越来越重要的角色，连接起DRAM和旋转磁盘之间的鸿沟。</p>

<p><img src="/images/2019/12/8.jpg" alt="" /></p>

<p>21.直写，就是立即将w的高速缓存块写回到紧接着的低一层中。虽然简单，但是直写的缺点是每次都会引起总线的流量。</p>

<p>写回，尽可能的推迟更新，只有当替换算法要驱逐这个更新过的块时，才把它写到紧接着的低一层中。由于局部性，写回能显著的减少总线流量，但是它的缺点是增加了复杂性。</p>

<p>虚拟内存系统（用主存作为存储在磁盘上的块的缓存）只使用写回。我们在现代系统的所有层次上都能看到写回缓存，其与处理读的方式相对称。</p>

<p>一般而言，高速缓存越往下层，越可能用写回而不是直写。</p>

<p>22.存储器系统的性能不是一个数字就能描述的，相反，它是一座时间和空间局部性的山。</p>

<h4 id="section-8">第二部分  在系统上运行程序</h4>

<h2 id="section-9">第七章 链接</h2>

<p>1.链接器把程序的各个部分联合成一个文件，处理器可以将这个文件加载到内存，并且执行它。</p>

<p>链接是将各种代码合数据片段收集并组合成为一个单一文件的过程。</p>

<p>链接可以执行于编译时，也就是在源代码被翻译成机器代码时；也可以执行于加载时，也就是在程序被加载器加载到内存并执行时；甚至执行于运行时，也就是由应用程序来执行。现代系统中，链接是由叫做链接器的程序自动执行的。</p>

<p>2.链接器在软件开发中扮演着一个关键的角色，因为它们使得分离编译成为可能。我们不用将一个大型的应用程序组织为一个巨大的源文件，而是可以把它分解为更小、更好管理的模块，可以独立的修改和编译这些模块。</p>

<p>3.许多软件产品在运行时使用共享库来升级压缩包装的二进制程序。大多数web服务器都依赖于共享库的动态链接来提供动态内容。</p>

<p>4.无论是什么样的操作系统，ISA或者目标文件格式，基本的链接概念是通用的。</p>

<p>5.大多数编译系统提供编译器驱动程序，它代表用户在需要时调用语言预处理器、编译器、汇编器和链接器。</p>

<p>6.静态链接：像Linux LD 程序这样的静态链接器以一组可重定位目标文件和命令行参数作为输入，生成一个完全</p>

<p>链接的、可以加载和运行的可执行目标文件作为输出。输入的可重定位目标文件由各种不同的代码合数据节组成，每一节都是一个连续的字节序列。指令在一节中，初始化了的全局变量在另一节中，而未初始化的变量又在另外一节中。</p>

<p>为了构造可执行文件，链接器必须完成两个主要任务：</p>

<p>①符号解析。目标文件定义和引用符号，每个符号对应于一个函数、一个全局变量或一个静态变量（即C语言中任何以static属性声明的变量）。符号解析的目的是将每个符号引用正好和一个符号定义关联起来。</p>

<p>②重定位。编译器和汇编器生成从地址0开始的代码和数据节。链接器通过把每个符号定义与一个内存位置关联起来，从而重定位这些节，然后修改所有对这些符号的引用，使得它们指向这个内存位置。</p>

<p>7.关于链接器的一些基本事实：目标文件纯粹是字节块的集合。这些块中，有些包含程序代码，有些包含程序数据，而其他的则包含引导链接器和加载器的数据结构。</p>

<p>8.目标文件由三种形式：</p>

<p>①可重定位目标文件，包含二进制代码和数据，其形式可以在编译时与其他可重定位目标文件合并起来，创建一个可执行目标文件。</p>

<p>②可执行目标文件，包含二进制代码和数据，其形式可以被直接复制到内存并执行。</p>

<p>③共享目标文件，一种特殊类型的可重定位目标文件，可以在加载或者运行时被动态的加载进内存并链接。</p>

<p>9.编译器和汇编器生成可重定位目标文件（包括共享目标文件）。链接器生成可执行目标文件。从技术上来说，一个目标模块就是一个字节序列，而一个目标文件就是一个以文件形式存放在磁盘中的目标模块。</p>

<p>10.一个典型的ELF可重定位目标文件包含下面几个节：</p>

<p>.text：已编译程序的机器代码。</p>

<p>.rodate：只读数据，比如printf语句中的格式串和开关语句的跳转表。</p>

<p>.data：已初始化的全局和静态C变量。局部C变量在运行时被保存在栈中，既不出现在.data节中，也不出现在.bss节中。</p>

<p>.bss：未初始化的全局和静态C变量，以及所有被初始化为0的全局或静态变量。在目标文件中这个节不占据实际的空间，它仅仅是一个占位符。在目标文件中，未初始化的变量不需要占据任何实际的磁盘空间。运行时，在内存中分配这些变量，初始值为0。</p>

<p>.symtab：一个符号变，它存放在程序中定义和引用的函数和全局变量的信息。实际上，每个可重定位目标文件在.symtab中都有一张符号表（除非程序员特意用STRIP 命令去掉它）。然而，和编译器中的符号表不同，.symtab符号表不包含局部变量的条目。</p>

<p>11.每个可重定位目标模块m都有一个符号表，它包含m定义和引用的符号的信息。在链接器的上下文中，有三种不同的符号：</p>

<p>①由模块m定义并能被其他模块引用的全局符号。</p>

<p>②由其他模块定义并被模块m引用的全局符号。</p>

<p>③只被模块m定义和引用的局部符号。</p>

<p>有趣的是，定义为带有C static属性的本地过程变量是不在栈中管理的。相反，编译器在.data或.bss中为每个定义分配空间，并在符号表忠创建一个有唯一名字的本地链接器符号。</p>

<p>在C中，源文件扮演模块的角色。任何带有static属性声明的全局变量或者函数都是模块私有的。类似的，任何不带static属性声明的全局变量和函数都是公共的，可以被其他模块访问。</p>

<p>12.符号表是由汇编器构造的，使用编译器输出到汇编语言.s文件中的符号。</p>

<p>13.链接器解析符号引用的方法是将每个引用与它输入的可重定位目标文件的符号表忠的一个确定的符号定义关联起来。静态局部变量也会有本地链接器符号，编译器还要确保它们拥有唯一的名字。</p>

<p>14.对全局符号的符号解析很棘手，还因为多个目标文件可能会定义相同名字的全局符号。在这种情况下，链接器必须要么标志一个错误，要么以某种方法选出一个定义并抛弃其他定义。</p>

<p>15.C++和Java中能使用重载函数，是因为编译器将每个唯一的方法和参数列表组合编码成一个对链接器来说唯一的名字。这种编码过程叫做重整，而相反的过程叫做恢复。</p>

<p>16.在编译时，编译器向汇编器输出每个全局符号，或者是强strong或者是弱weak。函数和已初始化的全局变量是强符号，未初始化的全局变量是弱符号。</p>

<p>根据强弱符号的定义，Linux链接器使用下面的规则来处理多重定义的符号名：</p>

<p>①不允许有多个同名的强符号；</p>

<p>②如果有一个强符号和多个弱符号同名，那么选择强符号；</p>

<p>③如果有多个弱符号同名，那么从这些弱符号中任意选择一个。</p>

<p>17.所有的编译系统都提供一种机制，将所有相关的目标模块打包称为一个单独的文件，称为静态库。它可以用作链接器的输入。当链接器构造一个输出的可执行文件时，它只复制静态库里被应用程序引用的目标模块。</p>

<p>静态库概念被提出来，以解决这些不同方法的缺点。相关的函数可以被编译为独立的目标模块，然后封装成一个单独的静态库文件。在链接时，链接器将只复制被程序引用的目标模块，这就减少了可执行文件在磁盘和内存中的大小。</p>

<p>18.在Linux系统中，静态库以一种称为存档archive的特殊文件格式存放在 磁盘中。存档文件是一组连接起来的可重定位目标 文件的集合，有一个头部用来描述每个成员目标文件的大小和位置。存档文件名由后缀.a标识。</p>

<p>19.任何Linux程序都可以通过调用execve函数来调用加载器，加载器将可执行目标文件中的代码合数据从磁盘复制到内存中，然后通过跳转到程序的第一条指令或入口点来运行该程序。这个将程序复制到内存并运行的过程叫做加载。</p>

<p>20.所谓内核就是操作系统驻留在内存的部分。</p>

<p>21.加载器的工作流程：</p>

<p><strong>当shell运行一个程序时，父shell进程生成一个子进程，它是父进程的一个复制。子进程通过execve系统调用启动加载器。加载器删除子进程现有的虚拟内存段，并创建一组新的代码、数据、堆和栈段。新的栈和堆段被初始化为零。通过将虚拟地址空间中的页映射到 可执行文件的页大小的片chunk，新的代码和数据段被初始化为可执行文件的内容。最后，加载器跳转到_start地址，它最终会调用应用程序的main函数。除了一些头部信息，在加载过程中没有任何从磁盘到内存的数据复制。直到CPU引用一个被映射的虚拟页时才会进行复制，此时，操作系统利用它的页面调度机制自动将页面从磁盘传送到内存。</strong></p>

<p>22.共享库是致力于解决静态库缺陷的一个现代创新产物。共享库是一个目标模块，在运行或加载时，可以加载到任意的内存地址，并和一个在内存中的程序链接起来。这个过程称为动态链接，是由一个叫做动态链接器的程序来执行的。共享库也称为共享目标，在Linux系统中通常用.so后缀来表示。微软的操作系统大量的使用了共享库，它们称为DLL动态链接库。</p>

<p>23.动态链接器本身就是一个共享目标。加载器不会像它通常所做的那样将控制传递给应用，而是加载和运行这个动态链接器。最后动态链接器将控制传递给应用程序。</p>

<p>24.应用程序还可能在它运行时要求动态链接器加载和链接某个共享库，而无需在编译时将那些库链接到应用中。</p>

<p>25.现代高性能的Web服务器可以使用基于动态链接的更有效和完善的方法来生成动态内容。其思路是将每个生成动态内容的函数打包在共享库中。当一个来自Web浏览器的请求到达时，服务器动态的加载和链接适当的函数，然后直接调用它，而不是使用fork额execve在子进程的上下文中运行函数。函数会一直缓存在服务器的地址空间中，所以只要一个简单的函数调用的开销就可以处理随后的请求了。在运行时无需停止服务器，就可以更新已存在的函数，以及添加新的函数。</p>

<p>26.Linux系统为动态链接器提供了一个简单的接口，允许应用程序在运行时加载和链接共享库：dlopen()。</p>

<p>dlsym()函数的输入是一个指向前面已经打开了的共享库的句柄和一个symbol名字，如果该符号存在，就返回符号的地址，否则返回NULL。</p>

<p>如果没有其他共享库还在使用这个共享库，dlclose()函数就卸载该共享库。</p>

<p>27.JNI Java本地接口，它允许Java程序调用本地的C和C++函数。JNI的基本思想是将本地C函数（如foo）编译到一个共享库中（如foo.so）。当一个正在运行的Java程序试图调用函数foo时，Java解释器利用dlopen接口动态链接和加载foo.so，然后再调用foo。</p>

<p>28.现代系统以这样一种方式编译共享模块的代码段，使得可以把它们加载到内存的任何位置而无需链接器修改。这样子，无限多个进程可以共享一个共享模块的代码段的单一副本。（当然，每个进程仍然会有它自己的读/写数据库）。</p>

<p>可以加载而无需重定位的代码称为位置无关代码（PIC）。用户对GCC使用-fpic选项指示GNU编译系统生成PIC代码。共享库的编译必须总是使用该选项。</p>

<p>在一个x86-64系统中，对同一个目标模块中符号的引用是不需要特殊处理使之成为PIC。可以用PC相对寻址来编译这些引用，构造目标文件时由静态链接器重定位。</p>

<p>29.无论我们在内存中的何处加载一个目标模块（包括共享目标模块），数据段与代码段的距离总是保持不变。因此，代码段中任何指令和数据段中任何变量之间的距离都是一个运行时常量，与代码段和数据段的绝对内存位置是无关的。</p>

<p>30.延迟绑定：将过程地址的绑定推迟到第一次调用该过程时。</p>

<p>把函数地址的解析推迟到它实际被调用的地方，能避免动态链接器在加载时进行成百上千个其实并不需要的重定位。</p>

<p>延迟绑定是通过两个数据结构之间简洁但又有些复杂的交互来实现的，这两个数据结构是：GOT全局偏移量表和过程连接表PLT。</p>

<p>31.Linux链接器支持一个很强大的技术，称为库打桩，它允许你截获对共享库函数的调用，取而代之执行自己的代码。</p>

<p>其基本思想：给定一个需要打桩的目标函数，创建一个包函数，它的原型与目标函数完全一样。使用某种特殊的打桩机制，你就可以欺骗系统调用包装函数而不是目标函数了。包装函数通常会执行它自己的逻辑，然后调用目标函数，再将目标函数的返回值传递给调用者。</p>

<p>打桩可以发生在编译时、链接时或当程序被加载和执行的运行时。</p>

<p>32.可以使用C预处理器在编译时打桩。Linux静态链接器支持用—wrap f标志进行链接时打桩。</p>

<p>编译时打桩需要能够访问程序的源代码，链接时打桩需要能够访问程序的可重定位对象文件。基于动态链接器的LD_PRELOAD环境变量可以实现运行时打桩。</p>

<p>如果LD_PRELOAD环境变量被设置为一个共享库路径名的列表，那么当你加载和执行一个程序，需要解析未定义的引用时，动态链接器会先搜索LO_PRELOAD库，然后才搜索任何其他的库。</p>

<p>你可以用LD_PRELOAD对任何可执行程序的库函数调用打桩。</p>

<p><img src="/images/2019/12/9.jpg" alt="" /></p>

<h2 id="section-10">第八章 异常控制流</h2>

<p>1.ECF异常控制流是操作系统用来实现I/O、进程和虚拟内存的基本机制。</p>

<p>应用程序通过使用一个叫做陷阱（trap）或者系统调用（system call）的ECF形式，向操作系统请求服务。比如，向磁盘写数据、从网络读取数据、创建一个新进程，以及终止当前进程，都是通过应用程序调用系统调用来实现的。</p>

<p>操作系统为应用程序提供了强大的ECF机制，用来创建新进程、等待进程终止、通知其他进程系统中的异常事件，以及检测和响应这些事件。</p>

<p>ECF是计算机系统中实现并发的基本机制。</p>

<p>像C++和Java这样的语言通过try、catch以及throw语句来提供软件异常机制。软件异常允许程序进行非本地跳转（即违反通常的调用/返回栈规则的跳转）来响应错误情况。非本地跳转是一种应用层ECF。</p>

<p>2.异常是异常控制流的一种形式，它一部分由硬件实现，一部分由操作系统实现。异常就是控制流中的突变，用来响应处理器状态中的某些变化。</p>

<p>在处理器中，状态被编码为不同的位和信号。状态变化称为事件。</p>

<p>3.在任何情况下，当处理器检测到有事件发生时，它就会通过一张叫做异常表的跳转表，进行一个间接过程调用（异常），到一个专门设计用来处理这类事件的操作系统子程序（异常处理程序exception handler）。</p>

<p>4.系统中可能的每种类型的异常都分配了一个唯一的非负整数的异常号。其中一些号码是由处理器的设计者分配的，其他号码是由操作系统内核的设计者分配的。</p>

<p>5.异常表的起始地址放在一个叫做异常表基址寄存器的特殊CPU寄存器里。</p>

<p>6.异常调用类似于过程调用，也有一些不同之处：</p>

<p>过程调用时，在跳转到处理程序之前，处理器将返回地址压入栈中。然而根据异常的类型，返回地址要么是当前指令（当事件发生时正在执行的指令），要么是下一条指令（如果事件不发生，将会在当前指令后执行的指令）。</p>

<p>处理器也把一些额外的处理器状态压到栈里，在处理程序返回时，重新开始执行被中断的程序会需要这些状态。</p>

<p>如果控制从用户程序转移到内核，所有这些项目都被压到内核栈中，而不是压到用户栈中。</p>

<p>异常处理程序运行在内核模式下，这意味着它们对所有的系统资源都有完全的访问权限。</p>

<p>7.一旦硬件触发了异常，剩下的工作就是由异常处理程序在软件中完成。在处理程序处理完事件之后，它通过执行一条特殊的“从中断返回”的指令，可选的返回到被中断的程序，该指令将适当的状态弹回到处理器的控制和数据寄存器中，如果异常中断的是一个用户程序，就将状态恢复为用户模式，然后将控制返回给被中断的程序。</p>

<p>8.异常可以分为四类：中断（interrupt）、陷阱（trap）、故障（fault）和终止（abort）。</p>

<p><img src="/images/2019/12/10.jpg" alt="" /></p>

<p>需要注意的是，中断是在当前指令执行完成之后，才把控制转移给中断处理程序。剩下的异常类型（陷阱、故障和终止）是同步发生的，是执行当前指令的结果。我们把这类指令叫做故障指令。</p>

<p>9.陷阱是有意的异常，是执行一条指令的结果。就像中断处理程序一样，陷阱处理程序将控制返回到下一条指令。陷阱最重要的用途是在用户程序和内核之间提供一个像过程一样的接口，叫做系统调用。</p>

<p>10.用户程序经常需要向内核请求服务，比如读一个文件（read）、创建一个新的进程（fork）、加载一个新的程序（execve），或者终止当前进程（exit）。为了允许对这些内核服务的受控的访问，处理器提供了一条特殊的“syscall n”指令，当用户程序想要请求服务n时，可以执行这条指令。执行syscall指令会导致一个到异常处理程序的陷阱，这个处理程序解析参数，并调用适当的内核程序。</p>

<p>11.系统调用和普通的函数调用，它们的实现非常不同。普通函数运行在用户模式中，用户模式限制了函数可以执行的指令的类型，而且它们只能访问与调用函数相同的栈。系统调用运行在内核模式中，内核模式允许系统调用执行特权指令，并访问定义在内核中的栈。</p>

<p>12.故障由错误情况引起的，它可能能够被故障处理程序修正。如果处理程序能够修正这个错误情况，它就将控制返回到引起故障的指令，从而重新执行它。否则，处理程序返回到内核中的abort例程，abort会终止引起故障的应用程序。</p>

<p>一个经典的故障示例是缺页异常。</p>

<p>13.终止是不可恢复的致命错误造成的结果，通常是一些硬件错误。</p>

<p>14.Segment fault：通常是因为一个程序引用一个未定义的虚拟内存区域，或者因为程序试图写一个只读的文本段。</p>

<p>15.每个系统调用都有一个唯一的整数号，对应于一个到内核中跳转表的偏移量（注意：这个跳转表和异常表不一样）。</p>

<p>16.C程序用syscall 函数可以直接调用任何系统调用。</p>

<p>在 x86-64 系统上，系统调用是通过一条称为syscall 的陷阱指令来提供的。</p>

<p>所有到Linux系统调用的参数都是通过调用寄存器而不是栈传递的。按照惯例，寄存器%rax 包含系统调用号，寄存器%rdi、%rsi、%rdx、%r10、%r8和%r9包含最多6个参数。从系统调用返回时，寄存器%rcx和%r11 都会被破坏，%rax 包含返回值。</p>

<p>17.进程的经典定义就是一个执行中的程序的实例。系统中的每个程序都运行在某个进程的上下文context中。上下文是由程序正确运行所需的状态组成的。这个状态包括存放在内存中的程序的代码和数据，它的栈、通用目的寄存器的内容、程序计数器、环境变量以及打开文件描述符的集合。</p>

<p>进程提供给应用程序的关键抽象：</p>

<p>一个独立的逻辑控制流，它提供一个假象，好像我们的程序独占的使用处理器。</p>

<p>一个私有的地址空间，它提供一个假象，好像我们的程序独占的使用内存系统。</p>

<p>18.PC值的序列叫做逻辑控制流，或者简称逻辑流。</p>

<p>19.一个逻辑流的执行在时间上与另一个流重叠，称为并发流。多个流并发的执行的一般现象被称为并发。一个进程和其他进程轮流运行的概念称为多任务。一个进程执行它的控制流的一部分的每一时间段叫做时间片。因此，多任务也叫做时间分片。</p>

<p>并发流的思想与流运行的处理器核数或者计算机数无关。如果两个流在时间上重叠，那么它们就是并发的，即使它们是运行在同一个处理器上。</p>

<p>并行流是并发流的一个真子集。如果两个流并发的运行在不同的处理器核或者计算机上，那么我们称它们为并行流，它们并行的运行，且并行的执行。</p>

<p>20.为了使操作系统内核提供一个无懈可击的进程抽象，处理器必须提供一种机制，限制一个应用可以执行的指令以及它可以访问的地址空间范围。</p>

<p>处理器通常用某个控制寄存器中的一个模式位来提供这种功能的，该寄存器描述了进程当前享有的特权。当设置了模式位时，进程就运行在内核模式中。一个运行在内核模式的进程可以执行指令集中的任何指令，并且可以访问系统中的任何内存位置。</p>

<p>没有设置模式位时，进程就运行在用户模式中。用户模式中的进程不允许执行特权指令。用户程序必须通过系统调用接口间接的访问内核代码和数据。</p>

<p>进程从用户模式变为内核模式的唯一方法是通过诸如中断、故障或者陷入系统调用这样的异常。</p>

<p>21.操作系统内核使用一种称为上下文切换的较高层形式的异常控制流来实现多任务。</p>

<p>内核为每个进程维持一个上下文context。</p>

<p>上下文就是内核重新启动一个被抢占的进程所需的状态。它由一些对象的值组成，这些对象包括通用目的寄存器、浮点寄存器、程序计数器、用户栈、状态寄存器、内核栈和各种内核数据结构，比如描述地址空间的页表，包含有关当前进程信息的进程表，以及包含进程已打开文件的信息的文件表。</p>

<p>22.在进程执行的某些时刻，内核可以决定抢占当前进程，并重新开始一个先前被抢占了的进程。这种决策就叫做调度。</p>

<p>在内核调度了一个进程的运行后，它就抢占当前进程，并使用一种称为上下文切换的机制来将控制转移到新的进程。</p>

<p>上下文切换：保存当前进程的上下文；恢复某个先前被抢占的进程被保存的上下文；将控制传递给这个新恢复的进程。</p>

<p><img src="/images/2019/12/11.jpg" alt="" /></p>

<p><img src="/images/2019/12/12.jpg" alt="" /></p>

<p>23.sleep系统调用，它显式的请求让调用进程休眠。</p>

<p>pause函数让调用函数休眠，直到该进程收到一个信号。</p>

<p>24.每个进程都有一个唯一的正数进程ID（PID）。getpid函数返回调用进程的PID。getppid函数返回它的父进程的PID。</p>

<p>25.从程序员的角度，我们可以认为进程总是处于下面三种状态之一：</p>

<p>运行。进程要么在CPU上执行，要么在等待被执行且最终会被内核调度。</p>

<p>停止。进程的执行被挂起，且不会被调度。</p>

<p>终止。进程永远的停止了，进程会因为三种原因终止：收到一个信号，该信号的默认行为是终止进程；从主程序返回；调用exit函数。</p>

<p>exit函数以status退出状态来终止进程。</p>

<p>26.父进程通过调用fork函数创建一个新的运行的子进程。子进程得到与父进程用户级虚拟地址空间相同的（但是独立的）一份副本，包括代码和数据段、堆、共享库以及用户栈、子进程还获得与父进程任何打开文件描述符相同的副本，这就意味着当父进程调用fork时，子进程还获得与父进程中打开的任何文件。父进程和新创建的子进程之间最大的区别在于它们有不同的PID。</p>

<p>fork函数只被调用一次，却会返回两次：一次是在调用进程（父进程）中，一次是在新创建的子进程中。在父进程中，fork返回子进程的PID。在子进程中，fork返回0。因为子进程的PID总是为非零，返回值就提供一个明确的方法来分辨程序是在父进程还是在子进程中执行。</p>

<p>27.当一个进程由于某种原因终止时，内核并不是立即把它从系统中清楚。相反，进程被保持在一种已终止的状态中国，直到被它的父进程回收。一个终止了但还未被回收的进程称为僵死进程。</p>

<p>如果一个父进程终止了，进程会安排 init 进程成为它的孤儿进程的养父。init 进程的PID为1，是在系统启动时由内核创建的，它不会终止，是所有进程的祖先。如果父进程没有回收它的僵死子进程就终止了，那么内核会安排 init 进程去回收他们。</p>

<p>一个进程可以通过调用 waitpid 函数来等待它的子进程终止或者停止。</p>

<p>28.execve 函数在当前进程的上下文中加载并运行一个新程序。 execve 加载并运行可执行目标文件，调用一次并从不返回。execve加载了filename之后，它调用启动代码，启动代码设置栈，并将控制传递给新程序的主函数。</p>

<p>29.程序和进程之间的区别：</p>

<p>程序是一堆代码合数据；程序可以作为目标文件存在于磁盘上，或者作为段存在于地址空间中。</p>

<p>进程是执行中程序的一个具体的实例；程序总是运行在某个进程的上下文中。</p>

<p>30.一种更高层的软件形式的异常，称为Linux信号，它允许进程和内核中断其他进程。</p>

<p>一个信号就是一条小消息，它通知进程系统发生了一个某种类型的事件。</p>

<p>每种信号类型都对应于某种系统事件。低层的硬件异常是由内核异常处理程序处理的，正常情况下，对用户进程而言是不可见的。信号提供了一种机制，通知用户进程发生了这些异常。</p>

<p><img src="/images/2019/12/13.jpg" alt="" /></p>

<p>31.传送一个信号到目的进程是由两个不同步骤组成的：</p>

<p>①发送信号。内核通过更新目的进程上下文中的某个状态，发送一个信号给目的进程。发送信号可以有如下两种原因：内核检测到一个系统事件，比如除零错误或者子进程终止；一个进程调用了kill 函数，显式的要求内核发送一个信号给目的进程。一个进程可以发送信号给它自己。</p>

<p>②接收信号。当目的进程被内核强迫以某种方式对信号的发送做出反应时，它就接收了信号。进程可以忽略这个信号，终止或者通过执行一个称为信号处理程序的用户层函数捕获这个信号。</p>

<p>一个发出而没有被接收的信号叫做待处理信号。在任何时刻，一种类型至多只会有一个待处理信号。如果一个进程有一个类型为k 的待处理信号，那么任何接下来发送到这个进程的类型为k 的信号都不会排队等待，它们只是被简单的丢弃。</p>

<p>一个待处理信号最多只能被接收一次。</p>

<p>32.默认的，一个子进程和它的父进程同属于一个进程组。一个进程可以通过使用setpgid 函数来改变自己或者其他进程的进程组。</p>

<p>33.一个为负的PID会导致信号被发送到进程组PID中的每个进程，比如kill 函数。</p>

<p>进程通过调用kill函数发送信号给其他进程（包括它们自己）。kill（pid, sig）。</p>

<table>
  <tbody>
    <tr>
      <td>如果pid 大于零，那么kill函数发送信号号码sig 给进程pid。如果pid 等于零，那么kill 发送信号sig 给调用进程所在进程组中的每个进程，包括调用进程自己。如果pid 小于零，kill 发送信号sig 给进程组</td>
      <td>pid</td>
      <td>（pid的绝对值）中的每个进程。</td>
    </tr>
  </tbody>
</table>

<p>34.进程可以通过调用alarm 函数向它自己发送SIGALRM信号。在任何情况下，对alarm 的调用都将取消任何待处理的闹钟。</p>

<p>35.当内核把进程p从内核模式切换到用户模式时，它会检查进程p的未被阻塞的待处理信号的集合。如果集合是非空的，那么内核选择集合中的某个信号k（通常是最小的k），并且强制p接受信号k。</p>

<p>36.进程可以通过signal 函数修改和信号相关联的默认行为。唯一的例外就是SIGSTOP和SIGKILL，它们的默认行为是不能修改的。</p>

<p>37.可以用volatile 类型限定符来定义一个变量，告诉编译器不要缓存这个变量。例如 volatile int g；</p>

<p>volatile限定符强迫编译器每次在代码中引用g时，都要从内存中读取g的值。</p>

<p>C提供一种整形数据类型 sig_atomic_t，对它的读和写保证会是原子（不可中断）的。</p>

<p>38.因为pending位向量中每种类型的信号只对应有一位，所以每种类型最多只能有一个未处理的信号。</p>

<p>39.不可以用信号来对其他进程中发生的事件计数。</p>

<p>40.Posix标准定义了sigaction函数，它允许用户在设置信号处理时，明确指定他们想要的信号处理语义。</p>

<p>41.C语言提供了一种用户级异常控制流形式，称为非本地跳转，它将控制直接从一个函数转移到另一个当前正在执行的函数，而不需要经过正常的调用-返回序列。非本地跳转是通过segjmp 和longjmp 函数来提供的。</p>

<p>setjmp 函数在env 缓冲区中保存当前调用环境，以供后面的longjmp使用，调用环境包括程序计数器、栈指针和通用目的寄存器。setjmp返回的值不能被赋值给变量。</p>

<p>setjmp 函数只被调用一次，但返回多次；longjmp 函数被调用一次，但从不返回。</p>

<p>42.非本地跳转的一个重要应用就是允许从一个深层嵌套的函数调用中立即返回，通常是由检测到某个错误情况引起的。如果在一个深层嵌套的函数调用中发现一个错误情况，我们可以使用非本地跳转直接返回到一个普通的本地化的错误处理程序，而不是费力的解开调用栈。</p>

<p>longjmp 允许它跳过所有中间调用的特性可能产生意外的后果。例如，如果中间函数调用中分配了某些数据结构，本来预期在函数结尾处释放它们，那么这些释放代码会被跳过，因而会产生内存泄漏。</p>

<p>非本地跳转的另一个重要应用是使一个信号处理程序分支到一个特殊的代码位置，而不是返回到被信号到达中断了的指令的位置。</p>

<p>可以把try 语句中的catch 子句看做类似于setjmp 函数。相似的，throw 语句就类似于longjmp 函数。</p>

<p>43.STRACE：打印一个正在运行的程序和它的子进程调用的每个系统调用的轨迹。</p>

<p>PS：列出当前系统中的进程（包括僵死进程）。</p>

<p>TOP：打印出关于当前进程资源使用的信息。</p>

<h2 id="section-11">第九章  虚拟内存</h2>

<p>1.为了更加有效的管理内存并且少出错，现代系统提供了一种对主存的抽象概念，叫做虚拟内存（VM）。它为每个进程提供了一个大的、一致的和私有的地址空间。</p>

<p>虚拟内存提供了三个重要的能力：①它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效的使用了主存。②它为每个进程提供了一致的地址空间，从而简化了内存管理。③它保护了每个进程的地址空间不被其他进程破坏。</p>

<p>2.虚拟内存给予应用程序强大的能力，可以创建和销毁内存片，将内存片映射到磁盘文件的某个部分，以及与其他进程共享内存。可以加载一个文件的内容到内存中，而不需要进行任何显式的复制。</p>

<p>3.现代处理器使用的是一种称为虚拟寻址的寻址方式。</p>

<p>将一个虚拟地址转换为物理地址的任务叫做地址翻译，地址翻译需要CPU硬件和操作系统之间的紧密合作。CPU芯片上叫做内存管理单元（MMU）的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。</p>

<p>4.地址空间是一个非负整数地址的有序集合，如果地址空间中的证书是连续的，那么我们说它是一个线性地址空间。一个地址空间的大小是由表示最大地址所需要的位数来描述的。例如一个包含N=2^n个地址的虚拟地址空间就叫做一个n位地址空间。</p>

<p>5.概念上而言，虚拟内存被组织为一个由存放在磁盘上的N个连续的字节大小的单元组成的数组。磁盘上的数据被分割成块，这些块作为磁盘和主存之间的传输单元。VM系统通过将虚拟内存分割为称为虚拟页的大小固定的块来处理这个问题。每个虚拟页的大小为P=2^p字节，类似的，物理内存被分割为物理页，大小也为P字节（物理页也被称为页帧）。</p>

<p>6.因为大的不命中处罚和访问第一个字节的开销，虚拟页往往很大，通常是4KB-2MB。由于大的不命中处罚，DRAM缓存是全相联的，即任何虚拟页都可以放置在任何的物理页中。</p>

<p>与硬件对SRAM缓存相比，操作系统对DRAM缓存使用了更复杂精密的替换算法。</p>

<p>因为对磁盘的访问时间很长，DRAM缓存总是使用写回，而不是直写。</p>

<p>因为DRAM是全相联的，所以任意物理页都可以包含任意虚拟页。</p>

<p>7.页表将虚拟页映射到物理页。页表就是一个页表条目（PTE）的数组。虚拟地址空间中的每个页在页表中一个固定偏移量处都有一个PTE。</p>

<p>8.DRAM缓存不命中称为缺页。缺页异常调用内核中的缺页异常处理程序，该程序会选择一个牺牲页。</p>

<p>9.实际上，虚拟内存工作的相当好，这主要归功于我们的老朋友局部性。</p>

<p>局部性原则保证了在任意时刻，程序将趋向于在一个较小的活动页面集合上工作，这个集合叫做工作集或者常驻集合。在初始开销，也就是将工作集页面调度到内存中之后，接下来对这个工作集的引用将导致命中，而不会产生额外的磁盘流量。</p>

<p>如果工作集的大小超出了物理内存的大小，那么程序将产生一种不幸的状态，叫做抖动，这时页面将不断的换进换出。</p>

<p>多个虚拟页面可以映射到同一个共享物理页面上。</p>

<p>10.按需页面调度和独立的虚拟地址空间的结合，对系统中内存的使用和管理造成了深远的影响。特别的，VM简化了链接和加载、代码和数据共享，以及应用程序的内存分配。</p>

<p>简化链接。独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际存放在物理内存的何处。这样的一致性极大的简化了链接器的设计和实现，允许链接器生成完全链接的可执行文件，这些可执行文件是独立于物理内存中代码和数据的最终位置的。</p>

<p>简化加载。加载器不从磁盘到内存实际复制任何数据。在每个页初次被引用时，要么是CPU取指令时引用的，要么是一条正在执行的指令引用一个内存位置时引用的，虚拟内存系统会按照需要自动的调入数据页。</p>

<p>将一组连续的虚拟页映射到任意一个文件中的任意位置的表示法称作内存映射。Linux提供一个称为mmap的系统调用，允许应用程序自己做内存映射。</p>

<p>简化共享。操作系统通过将不同进程中适当的虚拟页面映射到相同的物理页面，从而安排多个进程共享这部分代码的一个副本，而不是在每个进程中都包括单独的内核和C标准库的副本。</p>

<p>简化内存份额。当一个运行在用户进程中的程序要求额外的堆空间时，操作系统分配一个适当数字（例如k）个连续的虚拟内存页面，并且将它们映射到物理内存中任意位置的k个任意的物理页面。由于页表工作的方式，操作系统没有必要分配k个连续的物理内存页面。页面可以随机分散在物理内存中。</p>

<p>11.提供独立的地址空间使得区分不同进程的私有内存变得容易。但是，地址翻译机制可以以一种自然的方式扩展到提供更好的访问控制。因为每次CPU生成一个地址时，地址翻译硬件都会读一个PTE，所以通过在PTE上添加一些额外的许可位来控制对一个虚拟页面内容的访问十分简单。</p>

<p>如果一条指令违反了这些许可条件，那么CPU就触发一个一般保护故障，将控制传递给一个内核中的异常处理程序。Linux shell 一般将这种异常报告为 段错误 segment fault。</p>

<p>12.在任何既使用虚拟内存又使用SRAM高速缓存的系统中，都有应该使用虚拟地址还是使用物理地址来访问SRAM 高速缓存的问题。大多数系统是选择物理寻址的。使用物理寻址，多个进程同时在高速缓存中有存储块和共享来自相同虚拟页面的块成为很简单的事情。高速缓存无需处理保护问题，因为访问权限的检查是地址翻译过程的一部分。</p>

<p>13.内核虚拟内存包含内核中的代码和数据结构。有趣的是，Linux也将一组连续的虚拟页面（大小等于系统中DRAM的总量）映射到相应的一组连续的物理页面。这就为内核提供了一种便利的方法来访问物理内存中任何特定的位置。</p>

<p><img src="/images/2019/12/14.jpg" alt="" /></p>

<p>PS：有兴趣可以了解下用户栈和内核的区别和联系，以及数量对比关系（一对一，一对多还是多对多？）。</p>

<p>14.内核为系统中的每个进程维护一个单独的任务结构（源代码中的task_struct）。任务结构中的元素包含或者指向内核运行该进程所需要的所有信息（例如，PID、指向用户栈的指针、可执行目标文件的名字，以及程序计数器）。</p>

<p>15.因为一个进程可以创建任意数量的新虚拟内存区域（使用mmap函数），所以顺序搜索区域结构的链表花销可能会很大。因为实际上，Linux在链表中构建了一棵树，并在这棵树上进行查找。</p>

<p>16.Linux通过将一个虚拟内存区域与一个磁盘上的对象关联起来，以初始化这个虚拟内存区域的内容，这个过程称为内存映射。</p>

<p>17.一旦一个虚拟页面被初始化了，它就在一个由内核维护的专门交换文件之间换来换去。交换文件也叫做交换空间或者交换区域。</p>

<p>18.一个对象可以被映射到虚拟内存的一个区域，要么作为共享对象，要么作为私有对象。</p>

<p>19.私有对象使用一种叫做写时复制的巧妙技术被映射到虚拟内存中。</p>

<p>20.关于execve函数加载和执行程序的过程见下图：</p>

<p><img src="/images/2019/12/15.jpg" alt="" /></p>

<p>21.mmap(void* start, size_t length, int port, int flags, int fd, off_t offset)函数要求内核创建一个新的虚拟内存区域，最好是从地址start 开始的一个区域，并将文件描述符fd指定的对象的一个连续的偏映射到这个新的区域。连续的对象片大小为length字节，从距文件开始处偏移量为offset字节的地方开始。start地址仅仅是一个暗示，通常被定义为NULL。</p>

<p>munmap(void *start, size_t length) 函数删除从虚拟地址start 开始的，由接下来length 字节组成的区域。接下来对已删除区域的引用会导致段错误。</p>

<p>22.动态内存分配器维护着一个进程的虚拟内存区域，称为堆。对于每个进程，内核维护着一个变量brk，它指向堆的顶部。</p>

<p>23.显示分配器，要求应用显式的释放任何已分配的块。C++的new和delete操作符与C中的malloc和free相当。隐式分配器也叫做垃圾收集器，自动释放未使用的已分配的块的过程叫做垃圾收集。</p>

<p>24.malloc 不初始化它返回的内存。那些想要已初始化的动态内存的应用程序可以使用calloc，calloc 是一个基于malloc的瘦包装函数，它将分配的内存初始化为零。想要改变一个以前分配块的大小，可以使用realloc函数。</p>

<p>25.造成堆利用率很低的主要原因是一种称为碎片的现象，当虽然有未使用的内存但不能用来满足分配请求时，就发生这种现象。有两种形式的碎片：内部碎片和外部碎片。内部碎片是在一个已分配块比有效载荷大时发生的。外部碎片是当空闲内存合计起来足够满足一个分配请求，但是没有一个单独的空闲块足够大可以来处理这个请求时发生的。</p>

<p>因为外部碎片难以量化且不可能预测，所以分配器通常采用启发式策略来试图维持少量的大空闲块，而不是维持大量的小空闲块。</p>

<p>26.如果分配器不能为请求块找到合适的空闲块将发生什么呢？一个选择是通过合并那些在内存中物理上相邻的空闲块来创建一些更大的空闲块。如果还是不能生成一个足够大的块，那么分配器就会通过调用sbrk 函数，向内核请求额外的堆内存。</p>

<p>27.为了解决假碎片问题，任何实际的分配器都必须合并相邻的空闲块，这个过程称为合并。分配器可以选择立即合并，也就是在每次一个块被释放时，就合并所有的相邻块。或者它可以选择推迟合并，也就是等到某个稍晚的时候再合并空闲块。例如，分配器可以推迟合并，直到某个分配请求失败，然后扫描整个堆，合并所有的空闲块。</p>

<p>快速的分配器通常会选择某种形式的推迟合并。</p>

<p>28.C标准库中提供的GNU malloc 包就是采用的这种方法，因为这种方法既快速，对内存的使用也很有效率。</p>

<p>29.垃圾收集器是一种动态内存分配器，它自动释放程序不再需要的已分配块。在一个支持垃圾收集的系统中，应用显式分配堆块，但是从不显式的释放它们。</p>

<p>垃圾收集器将内存视为一张有向可达图。</p>

<p>30.像ML和Java这样的语言的垃圾收集器，对应用如何创建和使用指针有很严格的控制，能够维护可达图的一种精确的表示，因此也就能够回收所有垃圾。然而，诸如C和C++这样的语言的收集器通常不能维持可达图的精确表示。这样的收集器也叫做保守的垃圾收集器。</p>

<p>C程序的Mark &amp; Sweep收集器必须是保守的，其根本原因是C语言不会用类型信息来标记内存位置。</p>

<p>31.收集器可以按需提供它们的服务，或者它们可以作为一个和应用并行的独立线程，不断的更新可达图和回收垃圾。</p>

<p>32.虽然bss内存位置（诸如未初始化的全局C变量）总是被加载器初始化为零，但是对于堆内存却并不是这样的。一个常见的错误就是假设堆内存被初始化为零。</p>

<p>33.虚拟内存是为主存的一个抽象。虚拟内存提供三个重要的功能。第一，它在主存中自动缓存最近使用的存放磁盘上的虚拟地址空间的内容。虚拟内存缓存中的块叫做页。第二，虚拟内存简化了内存管理，进而又简化了链接、在进程间共享数据、进程的内存分配以及程序加载。最后，虚拟内存通过在每条页表条目中加入保护位，从而简化了内存保护。</p>

<p>34.内存映射为共享数据、创建新的进程以及加载程序提供了一种高效的机制。应用可以使用mmap函数来手工的创建和删除虚拟地址空间的区域。</p>

<h4 id="section-12">第三部分  程序间的交互和通信</h4>

<h2 id="io">第十章  系统级I/O</h2>

<p>1.输入/输出（I/O）是在主存和外部设备（例如磁盘驱动器、终端）之间复制数据的过程。</p>

<p>2.一个Linux文件就是一个m个字节的序列。所有的I/O设备（网络，磁盘和终端）都被模型化为文件，而所有的输入和输出都被当作对相应文件的读和写来执行。</p>

<p>3.打开文件时内核会返回一个小的非负整数，叫做描述符，它在后续对此文件的所有操作中标识这个文件。内核记录有关这个打开文件的所有信息。应用程序只需记住这个描述符。</p>

<p>Linux shell 创建的每个进程开始时都有三个打开的文件：标准输入（描述符为0）、标准输出（描述符为1）和标准错误（描述符为2）。</p>

<p>当应用完成了对文件的访问之后，它就通知内核关闭这个文件。作为响应，内核释放文件打开时创建的数据结构，并将这个描述符恢复到可用的描述符池中。无论一个进程因为何种原因终止时，内核都会关闭所有打开的文件并释放它们的内存资源。</p>

<p>4.文本文件是只含有ASCII或Unicode字符的普通文件，二进制文件是所有其他的文件。</p>

<p>5.目录是包含一组链接的文件，其中每个链接都将一个文件名映射到一个文件，这个文件可能是另一个目录。</p>

<p>套接字是用来与另一个进程进行跨网络通信的文件。</p>

<p>其他文件类型包含命名管道、符号链接，以及字符和块设备。</p>

<p>6.进程是通过调用open函数来打开一个已存在的文件或者创建一个新文件的。通过调用close函数关闭一个打开的文件。</p>

<p>关闭一个已关闭的描述符会出错。</p>

<p>通过调用lseek 函数，应用程序能够显示的修改当前文件的位置。</p>

<p>7.应用程序能够通过调用stat 和 fstat 函数，检索到关于文件的信息（有时也称为文件的元数据）。</p>

<p>8.内核用三个相关的数据结构来表示打开的文件：</p>

<p>描述符表。每个进程都有它独立的描述符表，它的表项是由进程打开的文件描述符来索引的。每个打开的描述符表项指向文件表中的一个表项。</p>

<p>文件表。打开文件的集合是由一张文件表来表示的，所有的进程共享这张表。每个文件表的表项组成包括当前的文件位置、引用计数，以及一个指向v-node表中对应表项的指针。关闭一个描述符会减少相应的文件表表项中的引用计数。内核不会删除这个文件表表项，直到它的引用计数为零。</p>

<p>v-node表。同文件表一样，所有的进程共享这张v-node表。每个表项包含stat结构中的大多数信息，包括st_mode和st_size 成员。</p>

<p><img src="/images/2019/12/16.jpg" alt="" /></p>

<p>9.多个描述符也可以通过不同的文件表表项来引用同一个文件。例如，如果以同一个filename调用open函数两次，就会发生这种情况。</p>

<p><img src="/images/2019/12/17.jpg" alt="" /></p>

<p>10.C语言定义了一组高级输入输出函数，称为标准I/O库。这个库libc 提供了打开和关闭文件的函数（fopen和fclose）、读和写字节的函数（fread和fwrite）、读和写字符串的函数（fgets和fputs），以及复杂的格式化的I/O函数（scanf和printf）。</p>

<p>标准I/O库将一个打开的文件模型化为一个流。每个ANSIC 程序开始时都有三个打开的流 stdin、stdout 和stderr ，分别对应于标准输入、标准输出和标准错误。</p>

<p>11.Unix I/O 模型是在操作系统内核中实现的。应用程序可以通过诸如open、close、lseek、read、write和stat这样的函数来访问Unix I/O。标准I/O函数提供了Unix I/O函数的一个更加完整的带缓冲的替代品。</p>

<p>12.对套接字使用lseek 函数是非法的。</p>

<p>13.建议在网络套接字上不要使用标准I/O 函数来进行输入和输出，而要使用健壮的RIO函数。如果你需要格式化的输出，使用sprintf函数在内存中格式化一个字符串，然后用 rio_writen把它发送到套接口。如果你需要格式化输入，使用rio_readlineb来读一个完整的文本行，然后用sscanf从文本行提取不同的字段。</p>

<h2 id="section-13">第十一章  网络编程</h2>

<p>1.客户端-服务器模型中的基本操作是事务。认识到客户端和服务器是进程，而不是常提到的机器或者主机，这是很重要的。</p>

<p>2.物理上而言，网络是一个按照地理远近组成的层次系统。最底层是LAN局域网，最流行的局域网是以太网。</p>

<p>在层次的更高级别中，多个不兼容的局域网可以通过叫做路由器的特殊计算机连接起来，组成一个Internet。每台路由器对于它所连接到的每个网络都有一个适配器（端口）。路由器也能连接高速点到点电话连接，这是称为WAN广域网的网络示例。</p>

<p>3.互联网络至关重要的特性是，它能由采用完全不同和不兼容技术的各种局域网和广域网组成。封装是互联网络的关键。</p>

<p>4.每台因特网主机都运行实现了TCP/IP协议的软件，几乎每个现代计算机系统都支持这个协议。因特网的客户端和服务器混合使用套接字接口函数和Unix I/O 函数来进行通信。通常将套接字函数实现为系统调用，这些系统调用会陷入内核，并调用各种内核模式的TCP/IP函数。</p>

<p>5.UDP 稍微扩展了IP协议，这样一来，包可以在进程间而不是在主机间传送。TCP 是一个构建在 IP 之上的复杂协议，提供了进程间可靠的全双工连接。</p>

<p>因特网主机上的进程能够通过连接和任何其他因特网主机上的进程通信。</p>

<p>6.TCP/IP 为任意整数数据项定义了统一的网络字节顺序（大端字节顺序）。在IP地址结构中存放的地址总是以（大端法）网络字节顺序存放的，即使主机字节顺序是小端法。</p>

<p>7.我们可以使用Linux的NSLOOKUP 程序来探究DNS 映射的一些属性。</p>

<p>8.因特网客户端和服务器通过在连接上发送和接收字节流来通信。从连接一对进程的意义上而言，连接是点对点的。从数据可以同时双向流动的角度来说，它是全双工的。</p>

<p>9.一个套接字是连接的一个端点。当客户端发起一个连接请求时，客户端套接字地址中的端口是由内核自动分配的，称为临时端口。然而，服务器套接字地址中的端口通常是某个知名端口，是和这个服务相对应的。例如，Web服务器通常使用端口80。</p>

<p>10.一个连接是由它两端的套接字地址唯一确定的。这对套接字地址叫做套接字对。</p>

<p><img src="/images/2019/12/18.jpg" alt="" /></p>

<p><img src="/images/2019/12/19.jpg" alt="" /></p>

<p>11.从Linux内核的角度来看，一个套接字就是通信的一个端点。从Linux程序的角度来看，套接字就是一个有相应描述符的打开文件。</p>

<p>12.客户端和服务器使用socket函数来创建一个套接字描述符。socket返回的clientfd描述符仅是部分打开的，还不能用于读写。客户端通过调用connect函数来建立和服务器的连接。connect函数会阻塞，一直到连接成功建立或是发生错误。</p>

<p>剩下的套接字函数——bind，listen和accept，服务器用它们来和客户端建立连接。</p>

<p>bind函数告诉内核将addr中的服务器套接字地址和套接字描述符sockfd联系起来。</p>

<p>服务器调用listen函数告诉内核，描述符是被服务器而不是客户端使用的。listen函数将socketfd从一个主动套接字转化为一个监听套接字。backlog 参数暗示了内核在开始拒绝连接请求之前，队列中要排队的未完成的连接请求的数量。通常我们会把它设置为一个较大的值，比如1024。</p>

<p>服务器通过调用accept函数来等待来自客户端的连接请求。</p>

<p>accept函数等待来自客户端的连接请求到达侦听描述符，然后在addr中填写客户端的套接字地址，并返回一个已连接描述符，这个描述符可被用来利用Unix I/O 函数与客户端通信。</p>

<p>监听描述符是作为客户端连接请求的一个端点。它通常被创建一次，并存在于服务器的整个生命周期。已连接描述符是客户端和服务器之间已经建立起来了的连接的一个端点。服务器每次接受连接请求时都会创建一次，它只存在于服务器为一个客户端服务的过程中。</p>

<p>在第一步中，服务器调用accept，等待连接请求到达监听描述符，具体的我们设定为描述符3。描述符0-2是预留给了标准文件的。</p>

<p>在第二步中，客户端调用connect函数，发送一个连接请求到listenfd。第三步，accept函数打开了一个新的已连接描述符connfd，在clientfd 和connfd 之间建立连接，并且随后返回connfd 给应用程序。</p>

<p><img src="/images/2019/12/20.jpg" alt="" /></p>

<p>13.有监听描述符和已连接描述符之间的区别，可以使得我们可以建立并发服务器，它能够同时处理许多客户端连接。例如，每次一个连接请求到达监听描述符时，我们可以派生（fork）一个新的进程，它通过已连接描述符与客户端通信。</p>

<p>14.客户端关闭描述符（close），这会导致发送一个EOF通知到服务器，当服务器从它的reo_readlineb函数收到一个为零的返回码时，就会检测到这个结果。</p>

<p>15.其实并没有EOF字符这样的一个东西。进一步来说，EOF是由内核检测到的一种条件。应用程序在它接收到一个由read函数返回的零返回码时，它就会发现出EOF条件。对于磁盘文件，当前文件位置超出文件长度时，会发生EOF。对于因特网连接，当一个进程关闭连接它的那一端时，会发生EOF。连接另一端的进程在试图读取流中最后一个字节之后的字节时，会检测到EOF。</p>

<p>16.如果一个服务器写一个已经被客户端关闭了的连接，那么第一次这样的写会正常返回，但是第二次就会引起发送SIGPIPE 信号。</p>

<h2 id="section-14">第十二章  并发编程</h2>

<p>1.当一个应用正在等待来自慢速I/O设备的数据到达时，内核会运行其他进程，使CPU保持繁忙。每个应用都可以按照类似的方式，通过交替执行I/O请求和其他有用的工作来利用并发。</p>

<p>2.使用应用级并发的应用程序称为并发程序。现代操作系统提供了三种基本的构造并发程序的方法：</p>

<p>①进程。用这种方法，每个逻辑控制流都是一个进程，由内核来调度和维护。因为进程有独立的虚拟地址空间，想要和其他流通信，控制流必须使用某种显示的进程间通信（IPC）机制。</p>

<p>②I/O 多路复用。在这种形式的并发编程中，应用程序在一个进程的上下文中显示的调度它们自己的逻辑流。逻辑流被模型化为状态机，数据到达文件描述符后，主程序显式的从一个状态转换到另一个状态。</p>

<p>③线程。线程是运行在一个单一进程上下文中的逻辑流，由内核进行调度。你可以把线程看成是其他两种方式的混合体，像进程流一样由内核进行调度，而像I/O多路复用流一样共享同一个虚拟地址空间。</p>

<p>3.对于在父、子进程间共享状态信息，进程有一个非常清晰的模型：共享文件表，但是不共享用户地址空间。进程有独立的地址空间既是优点也是缺点。为了共享信息，它们必须使用显示的IPC机制。基于进程的设计的另一个缺点是，它们往往比较慢，因为进程控制和IPC的开销很高。</p>

<p>4.waitpid函数和信号是基本的IPC机制，它们允许进程发送小消息到同一主机上的其他进程。套接字接口是IPC的一种重要形式，它允许不同主机上的进程交换任意的字节流。</p>

<p>5.I/O多路复用技术的基本思想，就是使用select函数，要求内核挂起进程，只有在一个或多个I/O事件发生后，才将控制返回给应用程序。</p>

<p>6.现代高性能服务器（例如Node.js，nginx和Tornado）使用的都是基于I/O多路复用的事件驱动的编程方式，主要是因为相比于进程和线程的方式，它有明显的性能优势。</p>

<p>事件驱动设计的一个优点是，它比基于进程的设计给了程序员更多的对程序行为的控制。</p>

<p>一个基于I/O多路复用的事件驱动服务器是运行在单一进程上下文中的，因此每个逻辑流都能访问该进程的全部地址空间。这使得在流之间共享数据变得很容易。</p>

<p>事件驱动设计常常比基于进程的设计要高效得多，因为它们不需要进程上下文切换来调度新的流。</p>

<p>事件驱动设计一个明显的缺点就是编码复杂。修改事件驱动服务器来处理部分文本行不是一个简单的任务，但是基于进程的设计却能处理得很好，而且是自动处理的。基于事件的设计另一个重要的缺点是它们不能充分利用多核处理器。</p>

<p>7.线程就是运行在进程上下文中的逻辑流。线程由内核自动调度，每个线程都有它自己的线程上下文，包括一个唯一的整数线程ID、栈、程序计数器、通用目的寄存器和条件码。所有的运行在一个进程里的线程共享该进程的整个虚拟地址空间。</p>

<p>8.同进程一样，线程由内核自动调度，并且内核通过一个整数ID来识别线程。同基于I/O多路复用的流一样，多个线程运行在单一进程的上下文中，因此共享这个进程虚拟地址空间的所有内容，包括它的代码、数据、堆、共享库和打开的文件。</p>

<p>9.一个线程的上下文要比一个进程的上下文小得多，线程的上下文切换要比进程的上下文切换快得多。</p>

<p>和一个进程相关的线程组成一个对等（线程）池，独立于其他线程创建的线程。主线程和其他线程的区别仅在于它总是进程中第一个运行的线程。对等（线程）池概念的主要影响是，一个线程可以杀死它的任何对等线程，或者等待它的任意对等线程终止。另外，每个对等线程都能读写相同的共享数据。</p>

<p>10.Posix线程（Pthreads）是在C程序中处理线程的一个标准接口。</p>

<p>线程通过调用pthread_create函数来创建其他线程。</p>

<p>新线程可以通过调用pthread_self函数来获得它自己的线程ID。</p>

<p>通过调用pthread_exit函数，线程会显式的终止。如果主线程调用pthread_exit，它会等待所有其他对等线程终止，然后再终止主线程和整个进程。</p>

<p>某个对等线程调用Linux的exit函数，该函数终止进程以及所有与该进程相关的线程。</p>

<p>另一个对等线程通过以当前线程ID作为参数调用pthread_cancel函数来终止当前线程。</p>

<p>线程通过调用pthread_join函数等待其他线程终止。pthread_join函数会阻塞，直到其他线程终止。pthread_join函数只能等待一个指定的线程终止，没有办法让pthread_wait等待任意一个线程终止。</p>

<p>11.在任何一个时间点上，线程是可结合的或者是分离的。一个可结合的线程能够被其他线程收回和杀死。在被其他线程回收之前，它的内存资源（例如栈）是不释放的。相反，一个分离的线程是不能被其他线程回收或杀死的。它的内存资源在它终止时由系统自动释放。</p>

<p>12.在现实程序中，有很好的理由要使用分离的线程。例如，一个高性能Web服务器可能在每次收到Web浏览器的连接请求时都创建一个新的对等线程。在这种情况下，每个对等线程都应该在它开始处理请求之前分离它自身，这样就能在它终止后回收它的内存资源了。</p>

<p>13.一组并发线程运行在一个进程的上下文中。每个线程都有它自己独立的线程上下文，包括线程ID、栈、栈指针、程序计数器、条件码和通用目的寄存器值。每个线程和其他线程一起共享进程上下文的剩余部分。这包括整个用户虚拟地址空间，它是由只读文本（代码）、读/写数据、堆以及所有的共享库代码和数据区域组成的。线程也共享相同的打开文件的集合。</p>

<p>14.寄存器是从不共享的，而虚拟内存总是共享的。</p>

<p>15.各自独立的线程栈的内存模型不是那么整齐清楚的。这些栈被保存在虚拟地址空间的栈区域中，并且通常是被相应的线程独立的访问的。我们说通常而不是总是，是因为不同的线程栈是不对其他线程设防的。所以，如果一个线程以某种方式得到一个指向其他线程栈的指针，那么它就可以读写这个栈的任何部分。</p>

<p>16.以提供互斥为目的的二元信号量常常也称为互斥锁。</p>

<p>17.饥饿就是一个线程无限期的阻塞，无法进展。</p>

<p>18.并行程序是一个运行在多个处理器上的并发程序。因此，并行程序的集合是并发程序集合的真子集。</p>

<p>19.并行编程的一项重要教训：同步开销巨大，要尽可能避免。如果无可避免，必须要用尽可能多的有用计算弥补这个开销。</p>

<p>20.有一类重要的线程安全函数，叫做可重入函数，其特点在于它们具有这样一种属性：当它们被多个线程调用时，不会引用任何共享数据。</p>

<p><img src="/images/2019/12/21.jpg" alt="" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[WWDC2019之启动时间与Dyld3]]></title>
    <link href="http://kobe1941.github.io/blog/launch-optimize-from-wwdc2019.html"/>
    <updated>2019-09-13T13:40:48+08:00</updated>
    <id>http://kobe1941.github.io/blog/launch-optimize-from-wwdc2019</id>
    <content type="html"><![CDATA[<p>WWDC从2016，2017到2019都有session对APP启动的过程以及如何优化做过介绍，WWDC2019因为把Dyld3开放给所有APP，所以Apple重新梳理了启动的各个阶段，并给出了对应的优化建议。</p>

<p>本文内容主要来自WWDC2019，图片取自WWDC的PPT或视频中截图；涉及到Dyld3的内容来自WWDC2017的一个session。</p>

<!--more-->

<h2 id="section">一、启动各个阶段的介绍</h2>

<p>启动类型</p>

<p><img src="/images/2019/09/13/1.png" alt="" /></p>

<p>1.最好是把启动时间控制在400ms内，因为这是启动动画的时间；系统要用100ms的时间来初始化APP，所以留给了你300ms的时间来构建你的第一个view；你可以懒加载或者异步加载数据。</p>

<p>2.iOS13带来了dyld3，虽然dyld3在WWDC2017的时候介绍过，但是iOS13终于带入了它；dyld3可以缓存runtime的dependency（库）来改善热启动的耗时。</p>

<p><code>
Dynamic Linker loads shared libraries and frameworks
Introduces caching of runtime dependencies to improve warm launch 
</code></p>

<p>启动的各个阶段</p>

<p><img src="/images/2019/09/13/2.png" alt="" /></p>

<p>3.为了充分利用dyld3带来的优化，苹果建议避免链接不使用的动态库，以及启动时避免使用类似DLOpen和NSBundleLoad的动态库的加载（loading），因为这会抵消缓存所带来的优势。最后就是你需要硬链接你的依赖dependency库，现在这个过程比之前更快了。（硬链接应该是dyld3自带的功能？）</p>

<p><img src="/images/2019/09/13/3.png" alt="" /></p>

<p>4.libSystemInit是System interface阶段的后面一部分内容，这是在给你的APP初始化低级别的系统组件，这个过程是固定的系统层面的消耗。开发者不必过多关注这个阶段。</p>

<p><code>
Initializes the interfaces with low level system components
System side work with a fixed cost 
</code></p>

<p>5.之后是runtime的初始化，这是系统在初始化Objective-C和Swift的runtime。一般的，在这一步你的APP不应该做任何事除非你有静态初始化函数，这些静态函数可能在你的代码里，也可能在你链接的库里。我们也不建议使用静态初始化（函数）。</p>

<p><code>
Initializes the language runtime
Invokes all class static load methods 
</code></p>

<p>如果你自己的framework里用到了静态初始化，可以考虑暴露API，以尽早初始化你的堆栈。——言下之意是用户在启动时主动调用该API，而不是写到+load函数里？</p>

<p>如果是必须要用到静态初始化，把代码从类的load函数里移动到initialize函数里去。</p>

<p><img src="/images/2019/09/13/4.png" alt="" /></p>

<p>6.UIKit 初始化。系统会在这一步实例化你的UIApplication和UIApplicationDelegate。这个阶段大部分是系统的工作，设置事件处理和系统集成/整合。你仍然可以影响这个阶段的耗时，比如子类化UIApplication，或者在UIApplicationDelegate的函数里做一些别的工作（通常是增大耗时o(╯□╰)o）。</p>

<p><code>
Instantiates the UIApplication and UIApplicationDelegate
Begins event processing and integration with the system 
</code></p>

<p><img src="/images/2019/09/13/5.png" alt="" /></p>

<p>7.之后是Application 的初始化。一般的回调顺序如下：</p>

<p><code>application:willFinishLaunchingWithOptions:</code></p>

<p><code>application:didFinishLaunchingWithOptions:</code></p>

<p>iOS13之前</p>

<p><code>applicationDidBecomeActive:</code></p>

<p>iOS13之后，新增了UISceneDelegate的代理回调函数</p>

<p><code>scene:willConnectToSession</code></p>

<p><code>sceneWillEnterForeground</code></p>

<p><code>sceneDidBecomeActive</code></p>

<p>苹果建议推迟跟第一屏展示不相关的工作，把这些工作放到后台去做或者全部推迟。</p>

<p>如果你采用了UIScenes的API，则可以在多个Scenes之间共享资源，这是为了避免多次去做不必要的工作。</p>

<p><img src="/images/2019/09/13/6.png" alt="" /></p>

<p>8.然后是Frist Frame Render阶段。首帧渲染过程为创建views，设置好布局，然后进行渲染。</p>

<p><code>loadView</code></p>

<p><code>viewDidLoad</code></p>

<p><code>layoutSubviews </code></p>

<p>这个阶段可以做的优化有：</p>

<p>减少视图view的数量；</p>

<p>减少视图view的层级（flattening your views）；</p>

<p>懒加载那些在启动过程中不会立即进行展示的view；</p>

<p>注意你的autolayout，尽量减少约束的数量；——干脆使用手动frame计算</p>

<p><img src="/images/2019/09/13/7.png" alt="" /></p>

<p>9.最后进入到Extended的阶段（延长/扩展阶段）。</p>

<p>从首帧后到最后一帧之间，APP的某个特定阶段；</p>

<p>异步加载数据的阶段；</p>

<p>不是所有APP都有这个阶段；</p>

<p>这个阶段时APP应该是可交互和可响应的；</p>

<p>可以用操作系统的 signpost API来标记和测量两个时间周期内的消耗。</p>

<p><code>Leverage os_signpost to measure work </code></p>

<p><img src="/images/2019/09/13/8.png" alt="" /></p>

<h2 id="section-1">二、测量启动</h2>

<p>1.测量启动过程</p>

<p>要去除掉网络和后台进程的干扰；</p>

<p><code>
Remove sources of variance to produce more consistent results
May result in launch times that are not representative
Use consistent results to evaluate progress
</code></p>

<p>2.tips关于设置干净和一致的测试环境</p>

<p>①重启手机，然后静置几分钟，用来清除任何启动时的工作；</p>

<p>②设置手机为飞行模式，或者使用Mock网络数据；</p>

<p>③iCloud在后台工作会干扰APP启动时间的测量，所以测量过程中使用不变的iCloud账号和不变的数据，或者干脆退出iCloud；</p>

<p>④使用release版本的APP进行测试，避免debug代码的干扰，还能享受编译器的优化（跟线上用户保持一致）；</p>

<p>⑤测试warm launch的数据，这样子可以保持更好的一致性，一部分APP的数据已经在内存里了，一部分系统服务也已经跑起来了；</p>

<p>⑥创造多个mock数据是非常重要的，比如用户数据量少和用户数据量多的情况，都要测量到；</p>

<p>⑦挑选多个设备来测试，并保证他们在测试过程中的一致性；一定要包含一些旧的设备，以及你的APP所支持的最旧的版本（指iOS操作系统版本）；</p>

<p>Xcode11开始，XCTest也提供了测量启动性能的API。只需要几行代码，Xcode就能重复启动你的APP，并提供启动性能的统计结果。</p>

<p><img src="/images/2019/09/13/9.png" alt="" /></p>

<p>3.测量的三个提示和技巧</p>

<p>①首先最小化你的启动过程；</p>

<p>最小化过程的时候，应该推迟任何跟展示首帧无关的操作，比如推迟暂时不展示的view或暂时用不到的功能的初始化；</p>

<p>千万不要block住主线程，不管是网络IO操作，文件IO操作还是其他，把这些移动到后台线程去；</p>

<p>减少内存的占用，内存的分配和操作是耗时的；</p>

<p><code>
Defer work unrelated to first frame
Move blocking work off main thread
Reduce memory usage 
</code></p>

<p>②然后按照优先级来安排你的启动过程；要保证这些工作的安排是合适的；</p>

<p>这意味着把不同优先级的工作安排到不同的线程去执行比以往任何时候都更重要。</p>

<p>可以关注一下WWDC 2017对GCD的深入介绍，讲了怎么正确的使用并行队列。</p>

<p><code>
Identify the right QoS for your task
Utilize scheduler optimizations for app launch
Preserve the priority with the right primitives 
</code></p>

<p>③最后对这些过程进行优化；</p>

<p>在启动过程中，应该限制到只去拉去自己需要的数据；</p>

<p>优化算法和数据结构；——指不要把启动时需要的数据结构搞的太复杂，造成拉取太多并不需要的数据</p>

<p>你应该缓存你的资源和计算结果，这是为了降低在做多次不必要的操作时产生的CPU和内存消耗；</p>

<p><code>
Simplify or limit existing work
Optimize algorithms and data structures
Cache resources and computations 
</code></p>

<p>4.Apple新带来的启动监控方式  <strong>MetricKit</strong></p>

<p>可以收集电源和性能统计数据，每24小时汇总数据进行上报。</p>

<p>&#8220;`
Collect custom power and performance metrics</p>

<p>Aggregated results delivered every 24 hours 
&#8220;`</p>

<h2 id="instrumentsxctestdemo-app">三、使用Instruments和XCTest来优化demo app的启动性能</h2>

<p>1.Instruments对demo APP的启动耗时进行分析</p>

<p>这一节主要是介绍了这个新的工具是如何使用的，直接看视频即可。</p>

<p>①Instruments重新编译APP会使用release模式</p>

<p><code>Xcode to recompile your app in release mode, so that you can take the advantages of compiler time optimizations.</code></p>

<p>②Xcode 11的Instruments提供了启动时间的模板，可以用来专门做这一块的性能统计和分析。</p>

<p><code>iOS 13, or Xcode 11, we now have the AppLaunchTemplate, which we can use specifically for triage purposes like this, figuring out what's wrong with AppLaunch.</code></p>

<p>2.分析各个线程</p>

<p><code>The first few phases marked in purple are the phases that occur before your main function is invoked within your app.</code></p>

<p>紫色表示pre-main阶段，在main函数执行前的阶段。</p>

<p><code>Onto the green phases, these phases of the early phases that occur at the very first of your main function, as your app finishes its launch and draws its first frame in UI.</code></p>

<p>绿色表示进入到main阶段。</p>

<p><code>Speaking of thread states, gray means it's blocked, meaning that the thread isn't doing any work.</code></p>

<p>灰色表示线程被block住了，该线程目前啥都没做。</p>

<p><code>Red means it's runnable, meaning that there's work scheduled to be done, but lacking CPU resources.</code></p>

<p>红色表示可执行，也就是待调度的状态，但是缺乏CPU资源。</p>

<p><code>Orange means it's preempted, meaning that it was doing work but got interrupted in favor of other competing work that has a higher priority.</code></p>

<p>orange代表该线程正在执行某个操作，但是被某个更高优先级的线程打断了，高优先级的线程完成了它才能继续执行。</p>

<p><code>And last but not least, blue means it's running, meaning that it's actually doing work on the CPU core.</code></p>

<p>蓝色表示正在运行中的线程，正在被CPU调度中。</p>

<p><img src="/images/2019/09/13/10.png" alt="" /></p>

<p>3.iOS系统进行的优化</p>

<p><code>Now notice that this initial phase only took 6 milliseconds as it sets up its system interfaces.</code></p>

<p><code>This is primarily due to the benefits of dyld3 introduction and third-party apps, in addition to other system layer enhancements.</code></p>

<p>system interface阶段只花了6ms，这是得益于dyld3和其他第三方APP，以及其他系统层面的优化。开发者可以不用写一行代码就能获得这些优化。</p>

<p><code>This discrepancy comes from the overhead of the profiling mechanism itself, which does give us a lot of information and insight, but has a cost of its own.</code></p>

<p>虽然这个阶段只花了6ms，但是因为instrumens的测量工具，导致总计花费了149ms，多出来的时间都是测量工具造成的。</p>

<p>但是如果使用XCTest的API来测量启动的性能数据，则不会有这个消耗。在demo APP中，使用Instruments的统计时间是500ms，而使用XCTest测量的时间是300ms，这个差值就是Instruments工具自身的消耗。</p>

<p>XCTest会去掉冷启动带来的数据干扰和误差，默认执行5次热启动，然后把数据汇总。</p>

<p><code>As mentioned before, dyld3 brings caching of your runtime dependencies to your apps, which you saw in the demo, that provided a huge improvement.</code></p>

<p>dyld3缓存了你的APP runtime的依赖库，这是一个很大的改善。</p>

<p><code> The Scheduler has also been optimized to help prioritize the work that happens during launch.</code></p>

<p>Scheduler也优化过以支持APP启动时区分优先级的工作。</p>

<p><code> We also put Auto Layout and Objective-C under the microscope and made a bunch of optimizations there.</code></p>

<p>我们同时优化了autolayout和OC的性能。</p>

<p><code>And then finally, we have exciting changes to app packaging coming later this year.</code></p>

<p>最后，我们会在今年晚些时候，带来APP打包方面的令人激动的改变。</p>

<p>Apple已经做的和即将要做的（app package）优化：</p>

<p><img src="/images/2019/09/13/11.png" alt="" /></p>

<p><img src="/images/2019/09/13/12.png" alt="" /></p>

<h2 id="appletips">四、Apple给的关于启动的Tips</h2>

<p>①不要事后才想起来做优化，应该在开始写代码的时候就要注意，在每一次bug fixed/重构/功能开发的时候去注意性能；积少成多，如果刚开始的不注意一些微小的优化，后面就会积累变成很大的消耗，而且后期会很难找到原因；</p>

<p>②应该经常性的去测量APP的启动性能数据；</p>

<p>③关注一下Xcode organizer，你就能知道你的APP在线上的表现；在iOS13下，用户同意的情况下，Apple会每24小时会把APP的性能数据发送到你的Organizer；iOS13已经支持MetricKit，它可以把收集到的性能数据通过APP内的代理函数回调给开发者自己分析和使用；</p>

<p><img src="/images/2019/09/13/13.png" alt="" /></p>

<h2 id="dyld3">五、关于Dyld3</h2>

<p>本节内容主要来自WWDC2017。</p>

<p>Dyld3开放给第三方的APP，是iOS13之后第三方APP启动速度会变快的最大原因。</p>

<p>启动闭包（launch closure）：这是一个新引入的概念，指的是 app 在启动期间所需要的所有信息。比如这个 app 使用了哪些动态链接库，其中各个符号的偏移量，代码签名在哪里等等。</p>

<p><code>perform symbol lookups</code>这个步骤表示执行符号查找。（例如：如果你使用了printf()函数，就会查找printf是否在库系统中，找到它的地址，将它赋值到你的程序中的函数指针）。</p>

<p>Dyld2和Dyld3的对比</p>

<p><img src="/images/2019/09/13/14.png" alt="" /></p>

<p>Dyld2做的事情</p>

<p><img src="/images/2019/09/13/15.png" alt="" /></p>

<p>Dyld3做的事情</p>

<p><img src="/images/2019/09/13/16.png" alt="" /></p>

<p>详细展开其在APP进程外和APP进程内做的事情</p>

<p>上半部分表示进程外</p>

<p><img src="/images/2019/09/13/17.png" alt="" /></p>

<p>下半部分表示在进程内做的</p>

<p><img src="/images/2019/09/13/18.png" alt="" /></p>

<p><img src="/images/2019/09/13/19.png" alt="" /></p>

<p>dyld2是纯粹的in-process，也就是在程序进程内执行的，也就意味着只有当应用程序被启动的时候，dyld2才能开始执行任务。</p>

<h4 id="dyld-2">dyld 2主要工作流程为：</h4>

<p><code>
•dyld的初始化，主要代码在dyldbootstrap::start，接着执行dyld::main，dyld::main代码较多，是dyld加载的核心部分；
•检查并准备环境，比如获取二进制路径，检查环境变量，解析主二进制的image header等信息；
•实例化主二进制的image loader，校验主二进制和dyld的版本是否匹配；
•检查shared cache是否已经map，没有的话则先执行map shared cache操作；
•检查DYLD_INSERT_LIBRARIES，有的话则加载插入的动态库（实例化image loader）;
•执行link操作。这个过程比较复杂，会先递归加载依赖的所有动态库（会对依赖库进行排序，被依赖的总是在前面），同时在这阶段将执行符号绑定，以及rebase，binding操作；
•执行初始化方法。OC的+load以及C的constructor方法都会在这个阶段执行；
•读取Mach-O的LC_MAIN段获取程序的入口地址，调用main方法。
</code></p>

<h4 id="section-2">简化版：</h4>

<p>①解析 mach-o 文件，找到其依赖的库，并且递归的找到所有依赖的库，形成一张动态库的依赖图。iOS 上的大部分 app 都依赖几百个动态链接库（大部分是系统的动态库），所以这个步骤包含了较大的工作量。</p>

<p>②匹配 mach-o 文件到自身的地址空间</p>

<p>③进行符号查找（perform symbol lookups）：比如 app 中调用了 printf 方法，就需要去系统库中查找到 printf 的地址，然后将地址拷贝到 app 中的函数指针中</p>

<p>④rebase和binding：由于 app 需要让地址空间配置随机加载，所以所有的指针都需要加上一个基地址</p>

<p>⑤运行初始化程序，之后运行 main() 函数</p>

<p>那么这些步骤在性能、安全性和可测试性上应该如何被优化呢？</p>

<p>苹果提出了这样两点思路：</p>

<p>①识别安全性敏感的组件：解析 mach-o 文件并寻找依赖是安全性敏感的，因为恶意篡改的 mach-o 头部可以进行某些攻击，如果一个 app 使用了 @rpath，那么恶意修改路径或者将一些库插入到特定的地方，攻击者就可以毁坏 app。所以这部分工作需要被搬到进程外来完成，比如搬到一个 daemon 进程中。</p>

<p>②识别可以被缓存的部分：符号查找就是其中一个，因为在一个特定的库中，除非软件更新或者这个库被改变，不然每个符号都应该有固定的偏移量。</p>

<p>以上两点思路也是 dyld 3.0 的优化思路。在 dyld 3.0 中，mach-o 头部解析和符号查找工作完成后，这些执行结果会被作为“启动闭包（launch closure）”写入硬盘。</p>

<p>因此iOS操作系统的后台守护进程可以完成所有的这些工作。然后我们确定大量占用资源的部分，也就是占用缓冲的部分。它们是符号查找，因为在给定的库中，除非进行软件更新或者在磁盘上更改库，符号将始终位于库中的相同的偏移位置。</p>

<p>Dyld3中，将这些部分移到上层（图中红色的部分），然后向磁盘写入闭包处理 “Write closure to disk”。这样，启动闭包处理就成了启动程序的重要环节。稍后可以在APP的进程中使用 dyld 3包含的这三个部分，</p>

<p>启动闭包比mach-o更简单。它们是内存映射文件，不需要用复杂的方法进行分析。</p>

<p>我们可以简单的验证它们，这样可以提高速度。</p>

<p>dyld3是部分out-of-process，部分in-process。上图中，虚线之上的部分是out-of-process的，在App下载安装和版本更新的时候会去执行。</p>

<h4 id="dyld-3">dyld 3包含三个组件：</h4>

<p>①本APP进程外的Mach-O分析器/编译器；</p>

<p>在dyld 2的加载流程中，Parse mach-o headers和Find Dependencies存在安全风险（可以通过修改mach-o header及添加非法@rpath进行攻击），而Perform symbol lookups会耗费较多的CPU时间，因为一个库文件不变时，符号将始终位于库中相同的偏移位置，这两部分在dyld 3中将采用提前写入把结果数据缓存成文件的方式构成一个”lauch closure“（可以理解为缓存文件）。</p>

<p>它处理了所有可能影响启动速度的 search path，@rpaths 和环境变量；它解析 mach-o 二进制文件，分析其依赖的动态库，并且完成了所有符号查找的工作；最后它将这些工作的结果创建成了启动闭包，写入缓存，这样，在应用启动的时候，就可以直接从缓存中读取数据，加快加载速度。</p>

<p>这是一个普通的 daemon 进程，可以使用通常的测试架构。</p>

<p>out-of-process是一个普通的后台守护程序，因为从各个APP进程抽离出来了，可以提高dyld3的可测试性。</p>

<p>②本进程内执行”lauch closure“的引擎；验证”lauch closures“是否正确，把dylib映射到APP进程的地址空间里，然后跳转到main函数。此时，它不再需要分析mach-o header和执行符号查找，节省了不少时间。</p>

<p>③”lauch closure“的缓存：</p>

<p>iOS操作系统内置APP的”lauch closure“直接内置在shared cache共享缓存中，我们甚至不需要打开一个单独的文件；</p>

<p>而对于第三方APP，将在APP安装或更新版本时（或者操作系统升级时？）生成lauch closure启动闭包，因为那时候的系统库已经发生更改。这样就能保证”lauch closure“总是在APP打开之前准备好。启动闭包会被写到到一个文件里，下次启动则直接读取和验证这个文件。</p>

<p>在 iOS，tvOS，watchOS 中，一切（生成启动闭包）都是在 app 启动之前做完的。在 macOS 上，由于有 sideload app，进程内引擎会在首次启动时启动一个 daemon，之后就可以使用启动闭包了。总之大部分情景下，这些工作都在 app 启动之前完成了。</p>

<p>大部分的启动场景都不需要调用这个进程外的 mach-o 解析器。而启动闭包又比 MachO 简单很多，因为它是一个内存映射文件，解析和验证都非常简单，并且经过了良好的性能优化。所以 dyld 3.0 的引入，能让 app 的启动速度得到明显提升。</p>

<p>总体来说，dyld 3把很多耗时的操作都提前处理好了，极大提升了启动速度。</p>

<p>参考链接：</p>

<p>1.<a href="https://developer.apple.com/videos/play/wwdc2017/413/">WWDC2017 session 413</a></p>

<p>2.<a href="https://developer.apple.com/videos/play/wwdc2019/423/">WWDC2019 session 423</a></p>

<p>3.<a href="https://blog.csdn.net/Hello_Hwc/article/details/78317863">深入理解<strong>iOS App</strong>的启动过程</a></p>

<p>4.<a href="https://techblog.toutiao.com/2017/07/05/session413/"><strong>App</strong> 启动时间：过去，现在和未来</a></p>

<p>5.<a href="https://www.jianshu.com/p/96f66b0c943c"><strong>App</strong> 启动流程以及优化 <strong>WWDC 2017</strong></a></p>

<p>6.<a href="https://easeapi.com/blog/blog/83-ios13-dyld3.html">iOS 13中的改进和优化</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iOS APP内存优化记录]]></title>
    <link href="http://kobe1941.github.io/blog/memory.html"/>
    <updated>2019-05-20T21:42:39+08:00</updated>
    <id>http://kobe1941.github.io/blog/memory</id>
    <content type="html"><![CDATA[<p>APP在运行过程中，如果内存占用过高则会引起以下几个问题：</p>

<p>①被操作系统的守护进程给杀掉，无论是前台还是后台；</p>

<p>②耗电增大，手机发热；</p>

<p>③系统可能会运行卡顿（不是换入换出到磁盘，而是解压缩和重压缩内存）；</p>

<p>业务背景</p>

<p>因为我们APP的直播间要玩网页版的小游戏，比较耗内存，除了JS游戏本身降低内存消耗之外，native也需要释放更多的内存以提供给游戏使用，避免因为内存占用过大而被操作系统杀掉进程。</p>

<p>优化native本身的内存占用大体分为两部分：优化长期的内存占用和优化峰值内存占用。</p>

<!--more-->

<h2 id="section">理论上的技术方案</h2>

<h3 id="section-1">优化长期的内存占用</h3>

<p>1.内存泄漏问题；</p>

<p>要做内存优化，先要分析当前占用内存较大的页面或功能。尤其是直播间。</p>

<p>①开instruments来跟课，查看直播间的内存泄漏；</p>

<p>——需要高端一点的机器，比如iPad才能跑起来，低端机器跑不了instruments。</p>

<p>②集成MLeaksFinder库到开发的target，检测内存泄漏；</p>

<p>——不过这个库只能检查UIViewcontroller和其对应的UIView是否有泄漏，可以方便开发的时候发现问题。</p>

<p>③集成 <a href="https://github.com/facebook/FBMemoryProfiler">FBMemoryProfiler</a> 可视化工具，直接嵌入到 App 中，可以起到在 App 中直接查看内存使用情况，并筛选潜在泄漏OC对象的作用；</p>

<p>网上说instruments的leaks工具无法检测循环引用导致的内存泄漏，验证下是否属实；</p>

<p>——是真的，下图这种block和self形式的循环引用，instruments检测不出来</p>

<p><img src="/images/2019/05/20/1.png" alt="" /></p>

<p>2.不必要的单例；是否可以改造成懒加载，用的时候才去初始化，用完可以释放掉；这个主要是去排查代码逻辑看是否合理；</p>

<p>3.RN页面的内存占用问题见<a href="[http://bbs.reactnative.cn/topic/5550/rn%E5%86%85%E5%AD%98%E9%97%AE%E9%A2%98-%E5%86%85%E5%AD%98%E6%8C%81%E7%BB%AD%E5%A2%9E%E9%95%BF-%E7%9B%B4%E5%88%B0%E8%A2%AB%E7%B3%BB%E7%BB%9F%E6%9D%80%E6%AD%BB](http://bbs.reactnative.cn/topic/5550/rn内存问题-内存持续增长-直到被系统杀死)">这里</a></p>

<p>①列表的cell是否有复用，复用是否正确；</p>

<p>②图片是否用了大图，能不能改成小图；</p>

<p>③进入直播间时回收掉所有RN页面，在退出直播间后重新初始化RN页面。——已采用，效果显著，每个RN页面大概占用20-40M的内存。</p>

<p>当然RN页面占用内存过大的问题，最彻底的解决方案还是直接用native去重写，至少一级页面用native去实现，无论是内存，滑动响应速度等等的用户体验都会好很多。只不过我们权衡之后没有这么做而已。</p>

<p>4.大图片的使用方式，包括动画所用图片的初始化方式，UIImage的imageWithContentWithFile可以避免使用缓存，用完即释放，但是需要把图片放在bundle的目录下，而不是XCAssets里；</p>

<p>——对于降低峰值内存有一定效果，但是imageNamed方式图片的缓存，在APP退到后台或者受到内存警告时，如果未被使用则会被系统自动清理。所以该方式可以采用，但是不要有太高的心理预期。</p>

<p>5.图片下采样。大一点的图片（比如做动画用的图片），改用ImageIO的api，而不是直接imageWithNamed的方式来创建，详情见<a href="https://techblog.toutiao.com/2018/06/19/untitled-42/">这里</a> 和<a href="https://blog.csdn.net/TuGeLe/article/details/81137995">这里</a>；另实际显示的尺寸小于图片实际尺寸时可以降低采样率（下采样）；</p>

<p>——下采样的方式仅针对图片尺寸比实际显示的尺寸大的情况下才会降低内存消耗。由于效果并不明显，项目中并未使用该种方式。</p>

<p>对一张1500 × 2668的图片做测试发现</p>

<p>①使用普通的ImageWithNamed方式，APP退到后台再拉回前台，内存会被清理；</p>

<p>②使用ImageWithContentWithFile的方式，每次使用后内存被释放；——直播间可以采用</p>

<p>这两种方式的内存变化见下图：</p>

<p><img src="/images/2019/05/20/2.png" alt="" /></p>

<p>③使用下采样的方式，峰值内存降低了，但是丢弃图片后，整体占用的内存并未下降。暂不知该图片缓存释放的时机。</p>

<p><img src="/images/2019/05/20/3.png" alt="" /></p>

<p>④使用按比例缩放UIGraphicsBeginImageContext()，效果跟下采样类似，图片缓存在APP退到后台依然没有释放</p>

<p><img src="/images/2019/05/20/4.png" alt="" /></p>

<p>6.APP监听到内存警告或APP退到后台的通知时，释放一些可重建的非必要对象。</p>

<h3 id="section-2">优化峰值内存占用</h3>

<p>1.在合适的地方添加AutoreleasePool来及时释放内存，比如全局IM消息的接收和解析，视频回放的消息过滤等；</p>

<p>2.缓存的使用，比如系统的UIImage的imageWithNamed函数创建的对象，以及YYMemoryCache和SDImageCache来共享缓存，多个业务使用同一份内存缓存。</p>

<p>3.缓存释放时机，YYMemoryCache和SDImageCache以及系统的UIImage的imageWithNamed创建的图片对象，都会在APP退到后台时，或者收到内存警告时清理全部的内存缓存。</p>

<p>4.网络图片单张图片size过大监控，以及网络图片总内存大小限制；</p>

<p>5.<a href="https://github.com/Tencent/OOMDetector/issues">OOM捕捉</a></p>

<p>——最大的用处是用来分析短期内存增长过快的原因，同时可以获取C和C++的内存分配。需要权衡下是否引入。</p>

<p>OOM暂未支持bugly集成，获取的堆栈日志暂时没地方存放。且因为都用了fishhook，会跟 <a href="https://github.com/facebook/FBRetainCycleDetector">FBRetainCycleDetector</a> 冲突，暂不引入。</p>

<p>6.了解mmap，测试其在图片映射的内存降低数据；</p>

<p>SDWebImage使用NSData的dataWithContentOfFile的方式来读取图片到内存；</p>

<p>mmap主要是可以省略从内核空间拷贝到用户空间的这一步操作，其他省不掉。FastImage额外省略了图片解码，但是却是通过把解码后的图片写磁盘来实现的（解码后图片增大，读取的IO耗时也会增大）。另FastImage可以使图片字节对齐，避免CoreAnimation在渲染时做一次额外的拷贝操作。</p>

<p>7.vmmap分析Xcode抓到的memgraph内存信息，看看有什么收获；</p>

<p>——没必要，原理跟<a href="https://github.com/facebook/FBMemoryProfiler">FBMemoryProfiler</a>类似，还不如直接用<a href="https://github.com/facebook/FBMemoryProfiler">FBMemoryProfiler</a>。</p>

<p>ps：Facebook三件套 <a href="https://github.com/facebook/FBRetainCycleDetector">FBRetainCycleDetector</a>，<a href="https://github.com/facebook/FBAllocationTracker">FBAllocationTracker</a>和<a href="https://github.com/facebook/FBMemoryProfiler">FBMemoryProfiler</a>。</p>

<p>命令行有不少工具可以用来配合分析内存，比如vmmap，leaks和heap，见<a href="https://juejin.im/post/5b23dafee51d4558e03cbf4f">这里</a>。</p>

<h2 id="section-3">在我们项目中的实际应用</h2>

<h3 id="section-4">内存泄漏</h3>

<p>1.Instruments 的部分捕获结果</p>

<p>①AFNetworking的session</p>

<p><img src="/images/2019/05/20/5.png" alt="" /></p>

<p>②JSBridge的内存泄漏</p>

<p><img src="/images/2019/05/20/6.png" alt="" /></p>

<p><img src="/images/2019/05/20/7.png" alt="" /></p>

<p>③第三方库的泄漏</p>

<p><img src="/images/2019/05/20/8.png" alt="" /></p>

<p>原因见下图，是第三方的库里边，create出来的CF对象没有release掉：</p>

<p><img src="/images/2019/05/20/9.png" alt="" /></p>

<p>2.MLeaksFinder发现的部分内存问题</p>

<p>①巡堂和动画的view内存泄漏，block互相持有导致，已fixed。</p>

<p><img src="/images/2019/05/20/10.png" alt="" /></p>

<p><img src="/images/2019/05/20/11.png" alt="" /></p>

<p>②IAP的Header内存泄漏，动画的delegate强引用导致，在开始做动画的时候设置delegate，在动画结束后的回调里把delegate置空可以解决这个问题。</p>

<p><img src="/images/2019/05/20/12.png" alt="" /></p>

<p><img src="/images/2019/05/20/13.png" alt="" /></p>

<h3 id="section-5">内存峰值优化</h3>

<p>1.视频回放的业务，拖动进度条会有大量的string被分配内存，占据了快100M</p>

<p><img src="/images/2019/05/20/14.png" alt="" /></p>

<p>解决方案：在拖曳进度条时会过滤消息，在过滤消息的函数里加自动释放池，及时释放局部变量的内存。</p>

<p>2.另一块是由于IM群组的设计，很多用户不需要知道的别的小班的消息也会一起发过来，数据量会很大，在子线程进行高度计算时会产生大量的临时变量，此处也加一个自动释放池用来降低内存峰值。同时之前在<a href="[http://www.zoomfeng.com/blog/crash-anr.html](http://www.zoomfeng.com/blog/crash-anr.html)">另一篇文章</a>里曾经针对消息数据的过滤做过优化</p>

<p><img src="/images/2019/05/20/15.png" alt="" /></p>

<p><img src="/images/2019/05/20/16.png" alt="" /></p>

<p>之后的instruments内存监控如下：</p>

<p><img src="/images/2019/05/20/17.png" alt="" /></p>

<p>第一张图里红圈的string内存占用已经不再出现。</p>

<p>3.SSZPicMemoryTool优化网络图片的内存占用问题（通过SD下载的，包括native和RN），</p>

<p>——主要是通过SSZPicMemoryTool接管了native通过SDWebImage使用的网络图片，以及RN页面使用的网络图片。所以可以及时在使用时监控到内存超过阈值的单张图片。只需要不同的业务页面走查一遍即可发现。除了单张图片的最大size超出监控之外，还直接把YYCache里的LRU淘汰算法拿来用，用于避免网络图片占用的峰值内存过大。</p>

<p><img src="/images/2019/05/20/18.png" alt="" /></p>

<p>原理见下图，SSZPicMemoryTool接管了图片内存缓存的管理，包括读取，写入和淘汰。</p>

<p><img src="/images/2019/05/20/19.png" alt="" /></p>

<h3 id="section-6">业务逻辑优化和时间空间置换策略</h3>

<p>直播间玩H5的小游戏会比较吃内存，所以可以采用一些策略，在用户玩游戏的时候，先释放掉一些内存出来供游戏使用。我们采用的两个方案，一个是用户玩游戏时，把直播的视频画面给移除掉，仅播放音频，因为此时本身视频画面也是被游戏画面挡住的，所以没有太大必要。另一个就是由于RN页面消耗的内存比较大，采用进入直播间就释放掉外围的RN页面，等退出直播间再恢复。</p>

<p>H5游戏本身也做了一轮内存的优化，优化前后降低了一半左右的内存消耗，效果还是很明显的。</p>

<p>1.游戏时关闭视频，以及进入直播间后回收RN的内存优化效果</p>

<p>测试环境：iPhone8P + 无其他课堂互动(消息等) + 进入直播后稳定后采集数据，直接跳转到直播间，不经过试讲和课程页</p>

<p><img src="/images/2019/05/20/20.png" alt="" /></p>

<p>游戏中剔除视频可以优化部分内存：剔除视频渲染后直播间整体内存可以降低25~30M（占进入直播间后增加的 40~50%），接收解码等操作因为SDK没有屏蔽接口，可能需要obs端做改造，但剩余可优化空间不足了，预计最多可优化10~20M。</p>

<p>直播间外部的内存有优化空间：剔除RN后，进入首屏和进入直播间的内存降低了约 50M，RN占用的内存比较大，首屏39M也有待细化，这两部分可以跟进优化。</p>

<p>——进入APP后会占用约40M的内存，经过测试，这部分无法继续降低了，一个空的工程也需要消耗掉这么多的内存。</p>

<p>回收RN页面</p>

<p><img src="/images/2019/05/20/21.png" alt="" /></p>

<p>重新加载RN页面</p>

<p><img src="/images/2019/05/20/22.png" alt="" /></p>

<p>2.直播间游戏自身的内存占用优化（主要是JS做的）</p>

<p>WKWebView 是运行在另一个进程里，Network Loading 以及 UI Rendering 在其它进程中执行。在 WKWebView 的进程里当总体的内存占用比较大的时候，WebContent Process 会 crash，从而出现白屏现象。</p>

<p>WebContent Process 因为整机内存过大被系统kill掉的时候不可控，所以一般会在crash白屏的回调加reload的逻辑，故而出现游戏不断reload问题。</p>

<p>Webview的CPU和内存优化交给前端自己做，只需要关注native本身的优化即可。WebKit进程的内存消耗可以用Instruments的Activity Monitor组件看到。</p>

<p><img src="/images/2019/05/20/23.png" alt="" /></p>

<p>Instrument Activity Monitor + Allocations ，忽略IM和互动其他情况，只在音视频+测评、游戏的情况分析：</p>

<p><img src="/images/2019/05/20/24.png" alt="" /></p>

<h2 id="section-7">关于内存统计</h2>

<p>APP使用内存统计可以直接如下的函数，参考来自<a href="https://github.com/aozhimin/iOS-Monitor-Platform#memory">这里</a></p>

<p><code>
+ (NSInteger)getResidentMemory
{
    task_vm_info_data_t vmInfo;
    mach_msg_type_number_t count = TASK_VM_INFO_COUNT;
    kern_return_t result = task_info(mach_task_self(), TASK_VM_INFO, (task_info_t) &amp;vmInfo, &amp;count);
    if (result == KERN_SUCCESS) {
        return (NSInteger)vmInfo.phys_footprint; ///&lt; 应用使用的物理内存大小
    } else {
        return -1;
    }
}
</code></p>

<h3 id="shared-memory">shared memory</h3>

<p>共享内存可以提供跨进程访问的能力，不过如果你的App使用了别的进程创建的共享内存，那么Debug Navigator是不会将它计入你自己的内存总量的，不过vmmap会将它加入TOTAL中，所以可能会导致vmmap计算的内存量会大于Debug Navigator统计内存量。</p>

<p>Debug Navigator其实就是统计了当前进程的所有虚拟内存的Dirty Size + Swapped Size，当然还要剔除掉对第三方共享内存的使用量，当我们发现Debug Navigator的内存量飙高时，不仅仅要去关注Heap上的内存用量，更要关注VM Tracker中那些大Dirty Size的VM Region，这样才能更透彻的了解你的App究竟是怎样使用内存的。</p>

<h3 id="section-8">其他</h3>

<p><img src="/images/2019/05/20/25.png" alt="" /></p>

<h2 id="section-9">内存泄漏工具的使用</h2>

<h3 id="section-10">1.介绍</h3>

<p>在iOS的Dev的包里会集成腾讯的MLeaksFinder库和Facebook的FBMemoryProfiler三件套的库，作用都是用来检测内存泄漏的。</p>

<p>不同点在于，MLeaksFinder只用于检查页面和页面相关的view的内存泄漏，当发现有内存泄漏时，会用一个弹窗来做出提示。比如最常见的，你退出一个页面，2秒后如果该页面的内存还未释放，则会提示内存泄漏。</p>

<p>FBMemoryProfiler则可以检测所有类型的内存泄漏，原理是hook了系统的alloc和dealloc函数，跟instruments的功能类似，只不过更加轻量化，可以在APP运行时实时看到内存分配的情况，如果有对象内存泄漏，则会标红表示。</p>

<h3 id="mleaksfinder">2.MLeaksFinder使用指南</h3>

<p>很简单，在退出一个页面后，如果有弹出下图的弹窗，则说明该页面有内存泄漏，并且列出了具体的内存泄漏的对象。</p>

<p><img src="/images/2019/05/20/26.png" alt="" /></p>

<p>备注：这个列表是一个内存泄漏的链表指针，不一定每个对象都会泄漏，但至少有一个是发生了内存泄漏的，通常可能是最后一个，也可能是多个，比如上图其实XunTangTipView和LOTAnimationView都有内存泄漏。</p>

<p>另外就是默认的判断时间是2秒，实际测试发现有时候会有误伤，所以可以把时间间隔调大到3秒或者更大一些。</p>

<h3 id="fbmemoryprofiler">3.FBMemoryProfiler使用指南</h3>

<p>在Dev的pod里集成该库后，Dev的包，顶部会有一个小浮窗显示当前的总内存，点击后可以展开大图查看更多信息，如下图所示。</p>

<p><img src="/images/2019/05/20/27.png" alt="" /></p>

<p>当你认为某个时刻，可能有内存泄漏，或者想看看是否有内存泄漏时，可以点击下图的Mark Gen按钮，此时会生成一个当前内存状态相比前一个generation时的快照，点击Expand按钮，会展开一个列表，把所有的对象都列出来，红色的一栏则表示该对象有内存泄漏。</p>

<p><img src="/images/2019/05/20/28.png" alt="" /></p>

<p>左上方有一个输入款，可以用来进行过滤。</p>

<p>点击红色的那一栏，就能看到具体的内存泄漏的原因，如下图，nats库的实例跟timer互相强引用导致。</p>

<p><img src="/images/2019/05/20/29.png" alt="" /></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iOS知识结构]]></title>
    <link href="http://kobe1941.github.io/blog/ios-level-up.html"/>
    <updated>2019-05-12T18:06:44+08:00</updated>
    <id>http://kobe1941.github.io/blog/ios-level-up</id>
    <content type="html"><![CDATA[<p>计算机三大知识结构：数据结构和算法，网络，操作系统。</p>

<p>这里陈硕在知乎上有个补充：<a href="https://www.zhihu.com/question/21405835">https://www.zhihu.com/question/21405835</a>，主要是谈到了计算机体系结构，这一块涉及到各个层面知识的串联和整合。</p>

<p>本文不会讲的很详细，只是简单罗列一些知识点及其应用场景，具体怎么做不会展开。</p>

<p>主要分几块的内容：iOS开发相关，计算机知识结构，软实力和职业规划。</p>

<!--more-->

<h1 id="ios">一、iOS相关</h1>

<h3 id="ios-1">1.iOS基础知识</h3>

<p>OC语法，类别（系统类与自定义类的函数覆盖），协议与多重继承的关系，继承是用什么数据结构实现的（C++和OC）</p>

<p>引用计数与内存管理，ARC下什么情况需要自己管理内存</p>

<p>atomic的含义与内部实现，block是否必须用copy修饰？</p>

<p>数据库基础操作（sqlite）</p>

<p>NSThread/NSOperation/GCD使用</p>

<p>事件响应链与事件派发传递流程</p>

<p>H5与OC的交互</p>

<h3 id="ios-2">2.iOS进阶知识</h3>

<p>UI方面：CALayer与CoreAnimation做动画，CoreGraphic绘图，TextKit/CoreText图文混排。</p>

<p>正则表达式</p>

<p>图层混合，离屏渲染的原因及解决方案</p>

<p>UITableView卡顿及其解决方法</p>

<p>OC对象模型，isa与super指向图（可以增加函数和isa混写的基础）</p>

<p>KVC/KVO实现原理，ARC（<a href="http://blog.sunnyxx.com/2015/01/17/self-in-arc/">http://blog.sunnyxx.com/2015/01/17/self-in-arc/</a>），weak的实现原理，关联对象的原理，自动释放池的实现原理，（可变）数组和字典的实现原理</p>

<p>method swizzle和 isa swizzle</p>

<p>Block的实现原理与破解参数（方法签名），循环引用与解决方案</p>

<p>runtime的应用</p>

<p><a href="https://blog.ibireme.com/2015/05/18/runloop/">runloop的原理与应用</a>（对应安卓的looper以及前端的event loop），与线程的关系，子线程如何保活与销毁</p>

<p>GCD原理（线程池实现原理） ——类似UITableViewCell的缓存池</p>

<p>消息转发的流程，如何避免不能识别的方法崩溃</p>

<p>内存泄漏的常见场景及其解决方法，如何查找内存泄漏</p>

<p>Xcode如何调试EXC_BAD_ACCESS，常用LLDB调试命令有哪些</p>

<p>如何保证线程安全，比如数据库/文件/变量</p>

<p>NSProxy，NSHashTable与NSMapTable的应用场景</p>

<h3 id="section">3.高阶</h3>

<p>从HTTP请求到UIView渲染的流程和原理</p>

<p>JavascriptCore的原理</p>

<p>runtime的原理</p>

<p>崩溃库的原理，PLCrashreporter/KSCrash</p>

<p>卡顿监控和抓堆栈的原理</p>

<p>崩溃日志解析流程</p>

<p>APP与extension是如何共享数据的，Macport底层是用哪一种进程间通信方式来实现的</p>

<h3 id="section-1">4.开源库</h3>

<p>AFNetworking</p>

<p>SDWebImage/FastImageCache</p>

<p>YYCache</p>

<p>MJExtension/YYModel</p>

<p>ASDK</p>

<h3 id="section-2">5.技术专项</h3>

<p>安装包size</p>

<p>启动时间</p>

<p>流畅性/帧率</p>

<p>稳定性与主线程卡顿</p>

<p>内存消耗与内存泄漏</p>

<p>CPU使用率</p>

<p>网络优化（含弱网）</p>

<p>长连接心跳策略（参考微信）</p>

<h3 id="section-3">6.质量相关</h3>

<p>代码规范</p>

<p>持续集成</p>

<p>自动化测试</p>

<h3 id="section-4">7.其他</h3>

<p>直播几种协议的优缺点，如何性能调优，</p>

<p>直播是如何拿到第一帧开始显示的，直播的四大性能指标（直播的四大指标：画质、卡顿率、延时、秒开。画质和卡顿率要看传说的码率，码率高画质高，卡顿率也可能增大。延时跟直播协议直接相关。秒开则主要是减少GOP，即减少 I 帧在视频流的间隔。）</p>

<p>逆向</p>

<p>下拉刷新原理</p>

<p>数据安全（沙盒，HTTPS/二次加密，单次登录token）</p>

<p>代码安全（混淆加固）</p>

<p>音视频处理等特定领域，OpenGL，FFmpeg</p>

<p>iOS相关的推荐书籍</p>

<p><a href="https://book.douban.com/subject/24284008/">Objective-C 基础教程</a></p>

<p><a href="https://book.douban.com/subject/24720270/">Objective-C 高级编程</a></p>

<p><a href="https://book.douban.com/subject/25829244/">Effective Objective-C 2.0</a></p>

<p><a href="https://book.douban.com/subject/25976913/">iOS编程实战</a></p>

<p>逆向的书主要就以下两本，建议先看第一本再看第二本</p>

<p><a href="https://book.douban.com/subject/26363333/">iOS应用逆向工程 第2版</a></p>

<p><a href="https://book.douban.com/subject/30239776/">iOS应用逆向与安全</a></p>

<h1 id="section-5">二、计算机基础知识</h1>

<h3 id="section-6">1.网络知识</h3>

<p>HTTP/HTTPS（握手流程）</p>

<p>DNS（劫持）</p>

<p>TCP三次握手四次挥手/慢启动/滑动窗口/流量控制/拥塞控制/快速重传/延迟应答/捎带应答，Dos攻击与防护</p>

<p>第三次握手或第四次挥手如果丢包会如何处理？</p>

<p>UDP及其应用</p>

<p>IP（IPV4与IPV6）与数据链路</p>

<p>cookie与session的区别和联系</p>

<p>公钥加密算法，证书信任链和数字签名</p>

<p>HTTP短连接和长连接的区别和联系</p>

<p>从浏览器输入一个字符串后发生了什么？</p>

<p>网络相关推荐书籍</p>

<p><a href="https://book.douban.com/subject/25863515/">图解HTTP</a></p>

<p><a href="https://book.douban.com/subject/24737674/">图解TCP/IP</a></p>

<p><a href="https://book.douban.com/subject/10746113/">HTTP权威指南</a></p>

<p><a href="https://book.douban.com/subject/26960678/">计算机网络 [谢希仁] </a></p>

<h3 id="section-7">2.数据结构和算法</h3>

<p>数组，链表，哈希表的实现原理</p>

<p>串和KMP</p>

<p>二叉树，二叉排序树，AVL二叉平衡树，红黑树，B数和B+树</p>

<p>队列，栈和堆及其应用</p>

<p>图的最小连接路径（最小生成图），广度遍历与深度遍历</p>

<p>排序和查找算法，不同排序算法的适用场景，如何选择</p>

<p>递归与分治，动态规划和贪心算法</p>

<p><a href="https://book.douban.com/subject/6424904/">大话数据结构</a></p>

<p><a href="https://book.douban.com/subject/27008702/">剑指offer</a></p>

<p>如果是准备面试的话去LeetCode刷题目吧</p>

<h3 id="section-8">3.操作系统</h3>

<p>进程和线程，进程间通信和线程间通信的方式</p>

<p>进程的内存分布区域：代码区，常量区，数据区（已初始化和未初始化），堆和栈</p>

<p>不同锁的区别，什么情况下会死锁，怎么解决</p>

<p>存储管理与置换/淘汰算法</p>

<p>文件系统、数据库索引和B树B+树的关联</p>

<p>多处理机，多计算机和分布式系统的概念</p>

<p>用户态和内核态，用户线程和内核线程的关系/如何切换/映射关系</p>

<p>BSD层和Mach层</p>

<p><a href="https://book.douban.com/subject/3852290/">现代操作系统</a></p>

<p><a href="https://book.douban.com/subject/25870206/">深入解析Mac OS X 与 iOS操作系统</a></p>

<p><a href="https://book.douban.com/subject/5333562/">深入理解计算机系统</a></p>

<h3 id="section-9">4.设计模式和面向对象设计原则</h3>

<p>MVC，MVVM，单例，代理，观察者，中介者，组合模式</p>

<p>工厂模式/简单工厂</p>

<p>单一原则，依赖倒置原则，接口隔离原则，迪米特原则（最小知识原则），</p>

<p>无环依赖原则，开闭原则，里氏替换原则</p>

<p>时序图，流程图，UML类图，框架图</p>

<p><a href="https://book.douban.com/subject/2334288/">大话设计模式</a></p>

<h1 id="section-10">三、软实力</h1>

<p>沟通与表达</p>

<p>总结复盘与提炼/升华</p>

<p>支撑业务与个人成长/团队成长</p>

<p>个人与团队影响力（技术总结，SDK，培训等给其他团队带来价值）</p>

<h1 id="section-11">四、职业规划</h1>

<p>技术专家 or 技术管理</p>

<p>全栈 or 架构师</p>

<p>目前看到的国内的现象是，技术管理并不见得核心竞争力有多强，而且换公司之后的可复用性和可落地性，比走技术深度路线似乎更难。</p>

<p>另外全栈工程师的确很厉害，无论在创业公司还是大厂都很喜欢，但是全栈一定要有自己特别擅长的领域，就是说还是T型人才的路子，如果一个领域的技术都不深入，成为每个都会一点每个都不精的万金油，也很尴尬。</p>

<p>架构师的价值主要体现在服务器端，客户端来说，除非产品的DAU在百万以上，否则架构设计真正在推动项目往前走所体现的价值，并没有多大，也就是说，如果业务做不起来，架构设计的再精妙再先进，都没办法创造价值。而往往架构师又是脱离一线业务的，所以你会发现基本架构师都是在大厂的基础架构组做支撑，或者在某个明星项目里成为核心主力，但是在一般的创业公司，或者中小型的公司，则不见得都设有该岗位。。</p>

<p>整体上，技术方向也有风口这一说法，比如大数据在2013年那会儿就很火，千人千面的推荐算法很受欢迎，大厂招人给的溢价也高。现在则是人工智能的子分支，比如计算机视觉里的人脸识别，声音识别，或者自动驾驶等比较火爆。基本上要获得溢价，都是要在某个技术受欢迎，大厂愿意投资，而市场上人才比较紧缺的时候才行。一旦人才供需平衡了，或者技术的风口过了，溢价也容易往下掉。对于普通人来说，如果能抓住某次溢价，把身价往上走一个两个台阶，那还是很爽的，不过现在技术发展越来越成熟，往后的技术风口上的技术，门槛越来越高，像人工智能/自动驾驶这种，已经不是普通本科生能够靠自学学会的了，也不是普通智商的人能玩的转的。平常心吧~</p>

<p>网上看到的一个大神</p>

<p><img src="/images/2019/05/12/20.png" alt="" /></p>

<p>从图中的描述里，可以看出大神的过人之处，可以以此为榜样去学习和进步~</p>

<h3 id="section-12">写在最后</h3>

<p>技术能力的提升不是一个线性增长的过程，当你各方面的基础知识基本过关了之后，如果之后不知道如何深入可以尝试去做一些技术专项，最好是跟自己公司的项目有关联的技术专项，既能提升自己在某一块的技术水平，也能对公司有帮助，这是一个互惠互利的过程。</p>

<p>抛开音/视频，AR/VR这种特定领域的技术来说，在通用的技术栈上，如果不知道怎么继续深入了，那就去学习操作系统吧，深挖操作系统的原理和实现，会有很大的好处。目前本菜鸡也在往这个方向深入学习，希望跟大家共勉~</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[崩溃和卡顿]]></title>
    <link href="http://kobe1941.github.io/blog/crash-anr.html"/>
    <updated>2019-05-12T13:20:17+08:00</updated>
    <id>http://kobe1941.github.io/blog/crash-anr</id>
    <content type="html"><![CDATA[<p>本文尝试分析和总结一下崩溃和主线程卡顿(ANR)的原理，以及对应的部分解决方案和案例。</p>

<!--more-->

<h1 id="section">一、崩溃</h1>

<p>业界的崩溃率标准：</p>

<p><img src="/images/2019/05/12/1.png" alt="" /></p>

<p><img src="/images/2019/05/12/2.png" alt="" /></p>

<h3 id="section-1">1.崩溃的信号类型</h3>

<p>崩溃主要是由于 Mach 异常、Objective-C 异常（NSException）引起的，同时对于 Mach 异常，到了 BSD 层会转换为对应的 Signal 信号，那么我们也可以通过捕获信号，来捕获 Crash 事件。针对 NSException 可以通过注册 NSUncaughtExceptionHandler 捕获异常信息。</p>

<p>OC层的异常通常可以通过崩溃日志去case by case解决，异常信息会很充分，对号入座即可。</p>

<p>EXC_BAD_ACCESS  对应的子类型有SIGSEGV，SIGBUS，SIGILL。</p>

<p>完整的描述通常为 Exception Type: EXC_BAD_ACCESS (SIGSEGV)</p>

<p>SIGSEGV：一般是非法内存访问错误，比如访问了已经释放的野指针，或者C数组越界。是EXC_BAD_ACCESS的子集；</p>

<p>程序无效内存中止信号，比如访问已经释放的内存，或者访问没有权限访问的内存，写入只读的内存等。</p>

<p>SEGV:（Segmentation  Violation），代表无效内存地址，比如空指针，未初始化指针，栈溢出等；</p>

<p>SIGABRT：重复释放同一块内存两次会导致，或者手动调用abort()函数；或者iOS内存jetsam的SIGABRT，对应的kill信号。或某些情况下的C数组越界导致的SIGABRT</p>

<p>SIGBUS：非法地址，意味着指针所对应的地址是有效地址，但总线不能正常使用该指针。通常是未对齐的数据访问所致。是EXC_BAD_ACCESS的子集；</p>

<p>SIGILL：非法指令。SIG是信号名的通用前缀。ILL是 illegal instruction（非法指令） 的缩写。SIGILL 是当一个进程尝试执行一个非法指令时发送给它的信号。可执行程序含有非法指令的原因，一般也就是cpu架构不对，编译时指定的march和实际执行的机器的march不同。这种情况，因为工具链一样，连接脚 本一样，所以可执行程序可以执行，不会发生exec format error。但是会包含一些不兼容的指令。还有另外一种可能，就是程序的执行权限不够，比如在用户态下运行的程序只能执行非特权指令，一旦CPU遇到特权指 令，将产生illegal instruction错误。</p>

<p>有时候也会因为打印数据的时候参数类型不匹配导致SIGILL，见这个例子 <a href="https://blog.csdn.net/Cow_cz/article/details/72930343">https://blog.csdn.net/Cow_cz/article/details/72930343</a></p>

<p>非法指令[EXC_BAD_INSTRUCTION // SIGILL] 该进程试图执行非法或未定义的指令。该进程可能试图通过配置错误的函数指针跳转到无效地址。</p>

<p>在Intel处理器上，ud2操作码会导致EXC_BAD_INSTRUCTION异常，但通常用于捕获进程以进行调试。如果在运行时遇到意外情况，则Intel处理器上的Swift代码将以此异常类型终止。有关详细信息，请参阅<a href="https://juejin.im/post/5bdd78bc6fb9a049d2357ca2">https://juejin.im/post/5bdd78bc6fb9a049d2357ca2</a></p>

<p>SIGTRAP：跟踪陷阱EXC_BREAKPOINT / SIGTRAP</p>

<p>SIGTRAP 由断点指令或其它trap指令产生，由debugger使用。swift的空指针或类型转换失败也会导致此信号。</p>

<p>与异常退出类似，此异常旨在为附加的调试器提供在其执行的特定点中断进程的机会。您可以使用该__builtin_trap()函数从您自己的代码中触发此异常。如果未附加调试器，则终止该过程并生成崩溃报告。</p>

<p>较低级别的库（例如libdispatch）会在遇到致命错误时捕获进程。有关错误的其他信息可以在崩溃报告的“ 其他诊断信息”部分或设备的控制台中找到。</p>

<p>如果在运行时遇到意外情况，则Swift代码将以此异常类型终止，例如：</p>

<p>①具有nil值的非可选类型</p>

<p>②强制类型转换失败</p>

<p>SIGINT 程序终止(interrupt)信号, 在用户键入INTR字符(通常是Ctrl-C)时发出，用于通知前台进程组终止进程。</p>

<p>SIGPIPE 管道破裂。这个信号通常在进程间通信产生，比如采用FIFO(管道)通信的两个进程，读管道没打开或者意外终止就往管道写，写进程会收到SIGPIPE信号。此外用Socket通信的两个进程，写进程在写Socket的时候，读进程已经终止。</p>

<h3 id="bsdmach">2.BSD层和Mach层的含义</h3>

<p><img src="/images/2019/05/12/3.png" alt="" /></p>

<h3 id="section-2">3.如何拦截崩溃</h3>

<p>OC的异常可以针对性做处理，比如不能识别的方法，你可以动态去添加。数组越界或者字典空值则可以method swizzle拦截掉。</p>

<p>其他异常信号的拦截则参考<a href="http://www.zoomfeng.com/blog/plcrashreporter-1.html">PLC的实现</a>，从BSD层和Mach层都可以处理，不过保险起见，一般从Mach层捕获异常信号。</p>

<h3 id="section-3">4.如何分析和解决崩溃</h3>

<p>①SIGSEGV野指针，RN的例子；</p>

<p>②SIGTRAP，swift的nats库的例子。</p>

<p>③通用类型的崩溃，比如OC容器的越界和空值导致的，以及unrecognized selector sent to instance这种，可以通过<a href="https://github.com/kobe1941/FFExtension">FFExtension</a>直接拦截掉。</p>

<p>例子见下方。</p>

<p>野指针大全</p>

<p><img src="/images/2019/05/12/4.png" alt="" /></p>

<p>这里是调试一个Bad Memory Access的一些小技巧:</p>

<p>如果objc_msgSend或者objc_release在回溯(Backtraces)的顶部附近，这个进程可能是尝试给一个释放的对象发送消息。你应该用Zombies instrument(调试僵尸对象的工具)来更好的理解这个崩溃。</p>

<p>事实上Xcode的这几个工具还是挺有用处的：</p>

<p><img src="/images/2019/05/12/5.png" alt="" /></p>

<p>关于野指针的类型崩溃在objc_msgSend函数时的拓展阅读见<a href="&lt;https://blog.csdn.net/u010960265/article/details/82454436&gt;">这里</a> 。这篇文章分析了该函数的汇编实现，以及崩溃在不同汇编指令时的情况分析。</p>

<h1 id="section-4">二、卡顿</h1>

<h3 id="section-5">1.监控卡顿的原理</h3>

<p>解主线程的卡顿，首先要能够看懂卡顿的堆栈回溯，这里需要了解一下runtime里的消息发送的流程，runloop的流程，以及自动释放池的一些函数调用。</p>

<p>另外就是要理解bugly是如何监控卡顿的，这样子才能知道如何去修复卡顿的问题：</p>

<p><img src="/images/2019/05/12/6.png" alt="" /></p>

<p>这就是很多SDK会采用的主线程卡顿监控的原理了，只是在execssiveHandler去抓堆栈的具体实现上，可能会有一些不同。PLC则是通过暂停先主线程，然后读取寄存器状态，之后再恢复的方法来实现抓取线程堆栈信息的。不过据说这种策略耗时比较大？有知道其他更好更快策略的小伙伴麻烦告知一下~</p>

<h3 id="section-6">2.避免主线程卡顿的通用策略</h3>

<p>①不要在主线程做耗时操作，比如解析数据，高度计算，解压缩文件和IO操作；</p>

<p>②耗时的计算结果，应该缓存起来，比如cell的高度；</p>

<p>③尽量少的用同步操作，一定避免死锁；</p>

<p>④能在子线程做的事情，就不要在主线程去做，比如统计打点；</p>

<p>⑤大对象的销毁，可以在子线程去做，参考YYCache；</p>

<p>⑥代码逻辑是否合理，比如我们项目中视频回放处的数据过滤，过滤的大班而不是小班数据；</p>

<p>⑦对于TableView这样的列表，为了提高滑动时的帧率，其cell的层级和数量，应该尽可能的少，离屏渲染一定要控制住，另外就是手动计算frame要比autolayout的性能好的多。</p>

<p>不同布局方式的性能差异见这里 <a href="https://lpd-ios.github.io/2017/04/05/FlexBox-Weex/">https://lpd-ios.github.io/2017/04/05/FlexBox-Weex/</a> 和 <a href="https://draveness.me/layout-performance">https://draveness.me/layout-performance</a> 。</p>

<h1 id="section-7">三、技术优化的一般流程</h1>

<p>通常针对一个技术点做优化的时候，都要先了解清楚这个技术点有哪些流程，优化的方向往往是减少流程的数量，以及减少每个流程的消耗。</p>

<p>比如安装包size的减少，启动时间的降低，滑动帧率的提升，弱网下连接的优化（到达率），耗电量的降低。</p>

<p>例外的是稳定性和主线程卡顿，这两块是从异常日志反推的。</p>

<p>帧率因为Xcode提供的工具比较强大，可以监控整个渲染流程的消耗，所以一般都先用instruments去找问题，然后再去逐个解决。</p>

<h1 id="anr">四、崩溃和ANR的案例及其解决</h1>

<p>1.LDNetPing多线程访问property导致野指针，使用串行队列来解决，异步同步皆可；</p>

<p><img src="/images/2019/05/12/7.png" alt="" /></p>

<p>实际上线程安全除了串行队列之外，并行队列配合barrier也可以实现。当然通用的方案是加锁，比如互斥锁，读写锁等等。</p>

<p>2.SSZAppConfig的getServerConfig函数：</p>

<p>使用AFURLSessionManager要注意，manager和它内部的session循环引用了，原因是NSURLSession的sessionWithConfiguration:delegate:delegateQueue:函数，会对delegate做强引用，除非手动解除，否则就内存泄漏</p>

<p><img src="/images/2019/05/12/8.png" alt="" /></p>

<p>但是需要注意的一点是，sessionDidBecomeInvalidBlock的回调是在子线程，如果用户反复的切换前后台会导致getServerConfig这个函数被反复调用，同时session失效的概率也会增加，</p>

<p>某些情况下，会导致session失效后，manager来不及设置为nil，从而使用了失效的session去发起网络请求，导致崩溃。后来又修改为如下：</p>

<p><img src="/images/2019/05/12/9.png" alt="" /></p>

<p>不过遗憾的是，因为业务的原因，我们的用户会频繁切换前后台，所以线上还是会不可避免的有崩溃，故并没有去刻意避开内存泄漏的问题，反而是让其成为一个单例，不做释放的操作。即把block里session的finishTaskAndInvalidate函数调用给注释掉了。</p>

<p>3.RN野指针崩溃</p>

<p>以RCTImageLoader的canHandleRequest:函数为例，videoRegex这个值的创建并不是多线程安全的，多线程野指针的问题基本都可以通过加锁来解决</p>

<p>&#8220;`
- (BOOL)canHandleRequest:(NSURLRequest *)request</p>

<p>{</p>

<pre><code>NSURL *requestURL = request.URL;

static NSRegularExpression *videoRegex = nil;

if (!videoRegex) {

  NSError *error = nil;

  videoRegex = [NSRegularExpression regularExpressionWithPattern:@"(?:&amp;|^)ext=MOV(?:&amp;|$)"

 

                                                         options:NSRegularExpressionCaseInsensitive

 

                                                           error:&amp;error];

  if (error) {

    RCTLogError(@"%@", error);

  }

}

 

NSString *query = requestURL.query;

if (query != nil &amp;&amp; [videoRegex firstMatchInString:query

                                           options:0

                                             range:NSMakeRange(0, query.length)]) {

  return NO;

}

 

for (id&lt;RCTImageURLLoader&gt; loader in _loaders) {

    if (![loader conformsToProtocol:@protocol(RCTURLRequestHandler)] &amp;&amp;

        [loader canLoadImageURL:requestURL]) {

        return YES;

    }

}

return NO;
</code></pre>

<p>}</p>

<p>&#8220;`</p>

<p>&#8220;`
@implementation RCTImageLoader (Hook)</p>

<ul>
  <li>(BOOL)hook_canHandleRequest:(NSURLRequest *)request</li>
</ul>

<p>{</p>

<pre><code>static pthread_mutex_t mutex;

static dispatch_once_t onceToken;

dispatch_once(&amp;onceToken, ^{

    pthread_mutex_init(&amp;mutex, NULL);

});

pthread_mutex_lock(&amp;mutex);

BOOL result;

result = [self hook_canHandleRequest:request];

pthread_mutex_unlock(&amp;mutex);

 

return result;
</code></pre>

<p>}</p>

<p>@end</p>

<p>&#8220;`</p>

<p><strong>其他的RN野指针崩溃可以通过类似的方式来解决，只不过有时候要用递归锁。</strong></p>

<p>4.主线程卡死问题</p>

<p>有时候子线程会先拿到锁，主线程反而在等待，而子线程可能会同步的丢一个block到主线程，造成死锁。</p>

<p>RCTBatchedBridge+Hook.m里对线程做了加锁上的优化：</p>

<p>&#8220;`
- (id)hook_moduleForName:(NSString *)moduleName
{
    if (!moduleName || ![moduleName isKindOfClass:[NSString class]]) {
        return nil;
    }
    ///&lt; 这个函数会递归调用
    static NSRecursiveLock *lock;
    static dispatch_once_t onceToken;
    dispatch_once(&amp;onceToken, ^{
        lock = [[NSRecursiveLock alloc] init];
    });</p>

<pre><code>id value = nil;
if (![NSThread isMainThread]) {
    [lock lock];
    value = [self hook_moduleForName:moduleName];
    [lock unlock];
} else {
    ///&lt; 子线程有时候会同步丢一个block到主线程，避免死锁
    if ([lock tryLock]) {
        value = [self hook_moduleForName:moduleName];
        [lock unlock];
    } else {
        value = [self hook_moduleForName:moduleName];
    }
}
 
return value; } ```
</code></pre>

<p>5.页面退出后block继续执行导致的野指针问题</p>

<p><img src="/images/2019/05/12/11.png" alt="" /></p>

<p>如上图，第605行导致了野指针，看下方的代码，正好处于GCD的执行步骤，猜测是直播间的控制器已经销毁，self为nil导致的，GCD的queue这个值不能传nil，否则crash。</p>

<p><img src="/images/2019/05/12/12.png" alt="" /></p>

<p>bugly上的日志统计证实了猜测，确实是直播间退出后，block里的代码依然在执行导致崩溃。</p>

<p><img src="/images/2019/05/12/13.png" alt="" /></p>

<p>解决方案：在block对self进行强引用并判空。</p>

<p><img src="/images/2019/05/12/14.png" alt="" /></p>

<p>6.swift写的nats库的崩溃问题</p>

<p><img src="/images/2019/05/12/15.png" alt="" /></p>

<p>以下是源码</p>

<p><img src="/images/2019/05/12/16.png" alt="" /></p>

<p>因为这里的queue.async是一个异步操作，做成同步会更合适，避免时序问题导致莫名其妙对象被置nil。</p>

<p>另一个问题就是swift下不允许为nil的情况，此处因为是switch-case的语法，case的条件以及后面的指针解引用是不能传nil指针的，所以当inputstream如果是nil值时会造成SIGTRAP类型的崩溃，解决方案也就是对对象做判空，如下图：</p>

<p><img src="/images/2019/05/12/17.png" alt="" /></p>

<p>事实上Nats的崩溃在做完上述两个操作后（其实最根本的是对inputstream判空的操作），就没有出现SIGTRAP类型的崩溃了，也就是说不会再有值被莫名其妙的置nil导致崩溃。</p>

<p>7.self指针的问题</p>

<p><img src="/images/2019/05/12/18.png" alt="" /></p>

<p>上图提示为addSubview是野指针。</p>

<p>具体崩溃代码见下图</p>

<p><img src="/images/2019/05/12/19.png" alt="" /></p>

<p>原因是ARC对self指针为unsafe_unretained，当上图这个函数在调用还未完成时，页面退出或用其他方式把self回收了，此后继续addSubView:的参数传入self则会野指针。</p>

<p>具体原因见<a href="http://blog.sunnyxx.com/2015/01/17/self-in-arc/">sunny的这篇文章</a>。</p>

<p>解决方案为，用一个局部strong指针去强引用self。</p>

<p>8.ANR问题</p>

<p>卓越网校的ANR问题，基本是主线程做IO操作，或者解析数据造成的，处理起来也简单，把这些操作放到子线程去做基本就没问题。尤其是对于cell的高度计算，子线程算好高度再返回，是一个通用的做法，用时间换流畅度。</p>

<p>另有小部分ANR是autolayout造成的，而这些ANR分布在相对较旧性能较差的机器上，可以不用修改代码，只需要知道手动计算frame的方式比autolayout的性能要好就可以了。</p>

<p>9.一个解决ANR的骚操作</p>

<p>场景是某个接口数据请求回来后，先解析，然后如果数据命中某个逻辑则发通知去通知业务方做其他的操作，通知是同步的，导致函数调用栈太长执行的时间太久被bugly抓到了ANR。</p>

<p>解决方案是把一个操作拆分成两个步骤，后面的步骤放到下一个runloop去做。原理是这么操作既能让出一个优先级给系统去响应用户的手势操作，还能让bugly检测ANR的代码执行过去。</p>

<p>异步丢到main queue的block是在下一次runloop循环或者从休眠中唤醒后执行的，要注意到runloop的源码里，唤醒后执行操作，会去查看此次唤醒是来自source1的mach port还是来自dispatch_asyn的dispatchPort，这两个的具体执行是两个逻辑分支，是分开的而不是一起执行。对用户手势的响应是来自source1的port。</p>

<p><img src="/images/2019/05/12/10.png" alt="" /></p>
]]></content>
  </entry>
  
</feed>
